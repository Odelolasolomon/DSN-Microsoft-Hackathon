{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Disease Prediction Using Ensemble Algorithms and Deep learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from scipy.stats import uniform as sp_uniform   \n",
    "from scipy.stats import randint as sp_randint\n",
    "import shap \n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier,BaggingClassifier ,GradientBoostingClassifier\n",
    "import xgboost as xgb \n",
    "import catboost as cbt \n",
    "from sklearn import svm \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score,roc_curve,accuracy_score\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.feature_selection import f_regression, SelectKBest, f_classif\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Load the Heart Disease Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train = pd.read_csv('Train Dataset .csv')\n",
    "test = pd.read_csv('Test Dataset.csv')\n",
    "sample = pd.read_csv('Sample Submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7303, 15)\n",
      "(2697, 14)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape) \n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Assesment/Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7303, 15) Index(['Id', 'Age', 'Sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg',\n",
      "       'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'],\n",
      "      dtype='object')\n",
      "Id          0\n",
      "Age         0\n",
      "Sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display the first five rows\n",
    "train.head()\n",
    "\n",
    "# Print the number of rows and columns, and column names\n",
    "print(train.shape, train.columns)\n",
    "\n",
    "# Count the number of missing values\n",
    "print(train.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2697, 14) Index(['id', 'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg',\n",
      "       'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal'],\n",
      "      dtype='object')\n",
      "id          0\n",
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "test.head()\n",
    "\n",
    "# Print the number of rows and columns, and column names\n",
    "print(test.shape, test.columns)\n",
    "\n",
    "# Count the number of missing values\n",
    "print(test.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.corr()['target'].drop(\"target\").sort_values().plot(kind='bar', figsize=(7, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('darkgrid')\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.countplot(x = 'target', data = train)\n",
    "plt.title('Target Variable Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train.target\n",
    "train = train.drop(\"target\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.rename({\"Id\":\"id\", 'Age':'age', 'Sex':'sex'},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10000 entries, 0 to 2696\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   id        10000 non-null  int64  \n",
      " 1   age       10000 non-null  int64  \n",
      " 2   sex       10000 non-null  int64  \n",
      " 3   cp        10000 non-null  int64  \n",
      " 4   trestbps  10000 non-null  int64  \n",
      " 5   chol      10000 non-null  int64  \n",
      " 6   fbs       10000 non-null  int64  \n",
      " 7   restecg   10000 non-null  int64  \n",
      " 8   thalach   10000 non-null  int64  \n",
      " 9   exang     10000 non-null  int64  \n",
      " 10  oldpeak   10000 non-null  float64\n",
      " 11  slope     10000 non-null  int64  \n",
      " 12  ca        10000 non-null  int64  \n",
      " 13  thal      10000 non-null  int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>Rank_Sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16167</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11275</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>198</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13251</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>101</td>\n",
       "      <td>202</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19921</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11293</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>139</td>\n",
       "      <td>419</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692</th>\n",
       "      <td>14964</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>136</td>\n",
       "      <td>291</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2693</th>\n",
       "      <td>16774</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694</th>\n",
       "      <td>18884</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>457</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>10000</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>242</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>17660</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>133</td>\n",
       "      <td>481</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  \\\n",
       "0     16167   33    0   1       158   205    1        0      154      0   \n",
       "1     11275   53    1   2       198   154    0        1      104      0   \n",
       "2     13251   37    1   2       101   202    1        0      155      0   \n",
       "3     19921   75    0   0       113   306    1        2       88      1   \n",
       "4     11293   35    1   2       139   419    1        1      166      1   \n",
       "...     ...  ...  ...  ..       ...   ...  ...      ...      ...    ...   \n",
       "2692  14964   34    0   3       136   291    0        1      163      0   \n",
       "2693  16774   72    0   1       104   166    1        2       95      1   \n",
       "2694  18884   31    1   0       153   457    1        1      170      1   \n",
       "2695  10000   71    0   0       111   242    1        0      147      1   \n",
       "2696  17660   51    1   3       133   481    0        0       91      0   \n",
       "\n",
       "      oldpeak  slope  ca  thal  Rank_Sum  \n",
       "0         1.5      1   4     1      32.0  \n",
       "1         0.8      2   1     0      32.0  \n",
       "2         2.1      1   3     1      32.0  \n",
       "3         4.9      0   2     2      29.0  \n",
       "4         0.9      2   4     0      29.0  \n",
       "...       ...    ...  ..   ...       ...  \n",
       "2692      2.6      2   2     3      37.0  \n",
       "2693      0.3      0   2     2      27.0  \n",
       "2694      3.8      0   3     1      30.0  \n",
       "2695      5.3      0   1     2      34.0  \n",
       "2696      1.4      2   2     3      33.0  \n",
       "\n",
       "[10000 rows x 15 columns]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the ranking function\n",
    "def rank_4_3_2_1(x):\n",
    "    # Remove outliers using 3 standard deviations rule\n",
    "    no_outliers = x[(x - x.mean()).abs() <= 3 * x.std()]\n",
    "    q1 = no_outliers.quantile(0.25)\n",
    "    q2 = no_outliers.quantile(0.5)\n",
    "    q3 = no_outliers.quantile(0.75)\n",
    "    ranks = pd.Series(index=x.index)\n",
    "    ranks[x >= q3] = 2\n",
    "    ranks[(x >= q2) & (x < q3)] = 3\n",
    "    ranks[(x >= q1) & (x < q2)] = 4\n",
    "    ranks[x < q1] = 1\n",
    "    return ranks\n",
    "\n",
    "# Get a list of the column names\n",
    "columns = data.drop(\"id\", axis=1).columns.tolist()\n",
    "\n",
    "to_remove=[]\n",
    "# Iterate over each column, rank the values, and add the result to a new column\n",
    "for col in columns:\n",
    "    ranks = rank_4_3_2_1(data[col])\n",
    "    data[f\"{col}_rank\"] = ranks\n",
    "    to_remove.append(f\"{col}_rank\")\n",
    "\n",
    "# Calculate the sum of the ranks for each column\n",
    "rank_sums = data.filter(regex=\"_rank$\").sum(axis=1)\n",
    "\n",
    "# Add the rank sums as a new row to the DataFrame\n",
    "data[\"Rank_Sum\"] = rank_sums\n",
    "data = data.drop(to_remove, axis=1)\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Engineer new features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg',\n",
       "       'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'Rank_Sum'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define age groups\n",
    "bins = [0, 30, 40, 50, 60, float('inf')]\n",
    "labels = ['<30', '30-40', '40-50', '50-60', '60+']\n",
    "data['age_group'] = pd.cut(data['age'], bins=bins, labels=labels)\n",
    "\n",
    "# Define blood pressure categories based on JNC 9 guidelines\n",
    "bins_jnc9 = [0, 120, 129, 139, 140, float('inf')]\n",
    "labels_jnc9 = ['Normal', 'Elevated', 'Hypertension Stage 1', 'Hypertension Stage 2', 'Hypertension Crisis']\n",
    "data['bp_category'] = pd.cut(data['trestbps'], bins=bins_jnc9, labels=labels_jnc9)\n",
    "\n",
    "# Create new features\n",
    "data['cholesterol_age_ratio'] = data['chol'] / data['age']\n",
    "data['heart_rate_reserve'] = (220 - data['age']) - data['thalach']\n",
    "data['angina_chest_pain'] = data['exang'] * data['cp']\n",
    "data['bp_to_hr_ratio'] = data['trestbps'] / data['thalach']\n",
    "data['slope_age_ratio'] = data['slope'] / data['age']\n",
    "data['vessels_age_ratio'] = data['ca'] / data['age']\n",
    "data['high_fasting_blood_sugar'] = (data['fbs'] > 120).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                            int64\n",
       "age                           int64\n",
       "sex                           int64\n",
       "cp                            int64\n",
       "trestbps                      int64\n",
       "chol                          int64\n",
       "fbs                           int64\n",
       "restecg                       int64\n",
       "thalach                       int64\n",
       "exang                         int64\n",
       "oldpeak                     float64\n",
       "slope                         int64\n",
       "ca                            int64\n",
       "thal                          int64\n",
       "Rank_Sum                    float64\n",
       "age_group                   float64\n",
       "bp_category                 float64\n",
       "cholesterol_age_ratio       float64\n",
       "heart_rate_reserve            int64\n",
       "angina_chest_pain             int64\n",
       "bp_to_hr_ratio              float64\n",
       "slope_age_ratio             float64\n",
       "vessels_age_ratio           float64\n",
       "high_fasting_blood_sugar      int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Define columns to encode\n",
    "columns_to_encode = [\"age_group\", \"bp_category\"]\n",
    "\n",
    "# Initialize the encoder\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "# Fit and transform the selected columns\n",
    "data[columns_to_encode] = encoder.fit_transform(data[columns_to_encode])\n",
    "\n",
    "data.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(columns=['high_fasting_blood_sugar'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7303, 14), (2697, 14))"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([\"id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=data.iloc[:train.shape[0],]\n",
    "test= data.iloc[train.shape[0]:,]\n",
    "y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index = int(0.8 * train.shape[0])\n",
    "\n",
    "X_train=train.iloc[:split_index, :]\n",
    "X_test=train.iloc[split_index:, :]\n",
    "\n",
    "y_train=target.iloc[:split_index]\n",
    "y_test=target.iloc[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5842, 22)\n",
      "(1461, 22)\n",
      "(5842,)\n",
      "(1461,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>Rank_Sum</th>\n",
       "      <th>age_group</th>\n",
       "      <th>bp_category</th>\n",
       "      <th>cholesterol_age_ratio</th>\n",
       "      <th>heart_rate_reserve</th>\n",
       "      <th>angina_chest_pain</th>\n",
       "      <th>bp_to_hr_ratio</th>\n",
       "      <th>slope_age_ratio</th>\n",
       "      <th>vessels_age_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.435448</td>\n",
       "      <td>-1.000685</td>\n",
       "      <td>-0.452124</td>\n",
       "      <td>0.341500</td>\n",
       "      <td>-1.075714</td>\n",
       "      <td>1.006526</td>\n",
       "      <td>-1.228060</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>-1.006526</td>\n",
       "      <td>-0.907156</td>\n",
       "      <td>0.007523</td>\n",
       "      <td>1.393939</td>\n",
       "      <td>-0.450350</td>\n",
       "      <td>-0.216855</td>\n",
       "      <td>-1.502696</td>\n",
       "      <td>-0.572701</td>\n",
       "      <td>-0.214382</td>\n",
       "      <td>0.067142</td>\n",
       "      <td>-0.692345</td>\n",
       "      <td>-0.341351</td>\n",
       "      <td>0.553834</td>\n",
       "      <td>2.501343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.025949</td>\n",
       "      <td>0.999316</td>\n",
       "      <td>0.443539</td>\n",
       "      <td>1.630098</td>\n",
       "      <td>-1.474637</td>\n",
       "      <td>-0.993516</td>\n",
       "      <td>-0.005233</td>\n",
       "      <td>-0.850975</td>\n",
       "      <td>-1.006526</td>\n",
       "      <td>-1.300077</td>\n",
       "      <td>1.228338</td>\n",
       "      <td>-0.728579</td>\n",
       "      <td>-1.352596</td>\n",
       "      <td>-0.216855</td>\n",
       "      <td>0.133299</td>\n",
       "      <td>-0.572701</td>\n",
       "      <td>-1.194684</td>\n",
       "      <td>0.808153</td>\n",
       "      <td>-0.692345</td>\n",
       "      <td>1.608507</td>\n",
       "      <td>0.958370</td>\n",
       "      <td>-0.691960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.153548</td>\n",
       "      <td>0.999316</td>\n",
       "      <td>0.443539</td>\n",
       "      <td>-1.494754</td>\n",
       "      <td>-1.099180</td>\n",
       "      <td>1.006526</td>\n",
       "      <td>-1.228060</td>\n",
       "      <td>0.490591</td>\n",
       "      <td>-1.006526</td>\n",
       "      <td>-0.570367</td>\n",
       "      <td>0.007523</td>\n",
       "      <td>0.686433</td>\n",
       "      <td>-0.450350</td>\n",
       "      <td>-0.216855</td>\n",
       "      <td>-1.502696</td>\n",
       "      <td>1.626020</td>\n",
       "      <td>-0.437532</td>\n",
       "      <td>-0.056360</td>\n",
       "      <td>-0.692345</td>\n",
       "      <td>-1.172852</td>\n",
       "      <td>0.375535</td>\n",
       "      <td>1.249190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.524501</td>\n",
       "      <td>-1.000685</td>\n",
       "      <td>-1.347787</td>\n",
       "      <td>-1.108174</td>\n",
       "      <td>-0.285689</td>\n",
       "      <td>1.006526</td>\n",
       "      <td>1.217594</td>\n",
       "      <td>-1.271859</td>\n",
       "      <td>0.993516</td>\n",
       "      <td>1.001317</td>\n",
       "      <td>-1.213292</td>\n",
       "      <td>-0.021073</td>\n",
       "      <td>0.451895</td>\n",
       "      <td>-1.140675</td>\n",
       "      <td>0.951297</td>\n",
       "      <td>1.626020</td>\n",
       "      <td>-0.846515</td>\n",
       "      <td>0.659951</td>\n",
       "      <td>-0.692345</td>\n",
       "      <td>0.231957</td>\n",
       "      <td>-1.095430</td>\n",
       "      <td>-0.448627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.294498</td>\n",
       "      <td>0.999316</td>\n",
       "      <td>0.443539</td>\n",
       "      <td>-0.270585</td>\n",
       "      <td>0.598200</td>\n",
       "      <td>1.006526</td>\n",
       "      <td>-0.005233</td>\n",
       "      <td>0.779948</td>\n",
       "      <td>0.993516</td>\n",
       "      <td>-1.243945</td>\n",
       "      <td>1.228338</td>\n",
       "      <td>1.393939</td>\n",
       "      <td>-1.352596</td>\n",
       "      <td>-1.140675</td>\n",
       "      <td>-1.502696</td>\n",
       "      <td>0.160206</td>\n",
       "      <td>1.493142</td>\n",
       "      <td>-0.278664</td>\n",
       "      <td>1.118166</td>\n",
       "      <td>-0.760309</td>\n",
       "      <td>2.014610</td>\n",
       "      <td>2.285228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex        cp  trestbps      chol       fbs   restecg  \\\n",
       "0 -1.435448 -1.000685 -0.452124  0.341500 -1.075714  1.006526 -1.228060   \n",
       "1 -0.025949  0.999316  0.443539  1.630098 -1.474637 -0.993516 -0.005233   \n",
       "2 -1.153548  0.999316  0.443539 -1.494754 -1.099180  1.006526 -1.228060   \n",
       "3  1.524501 -1.000685 -1.347787 -1.108174 -0.285689  1.006526  1.217594   \n",
       "4 -1.294498  0.999316  0.443539 -0.270585  0.598200  1.006526 -0.005233   \n",
       "\n",
       "    thalach     exang   oldpeak     slope        ca      thal  Rank_Sum  \\\n",
       "0  0.464286 -1.006526 -0.907156  0.007523  1.393939 -0.450350 -0.216855   \n",
       "1 -0.850975 -1.006526 -1.300077  1.228338 -0.728579 -1.352596 -0.216855   \n",
       "2  0.490591 -1.006526 -0.570367  0.007523  0.686433 -0.450350 -0.216855   \n",
       "3 -1.271859  0.993516  1.001317 -1.213292 -0.021073  0.451895 -1.140675   \n",
       "4  0.779948  0.993516 -1.243945  1.228338  1.393939 -1.352596 -1.140675   \n",
       "\n",
       "   age_group  bp_category  cholesterol_age_ratio  heart_rate_reserve  \\\n",
       "0  -1.502696    -0.572701              -0.214382            0.067142   \n",
       "1   0.133299    -0.572701              -1.194684            0.808153   \n",
       "2  -1.502696     1.626020              -0.437532           -0.056360   \n",
       "3   0.951297     1.626020              -0.846515            0.659951   \n",
       "4  -1.502696     0.160206               1.493142           -0.278664   \n",
       "\n",
       "   angina_chest_pain  bp_to_hr_ratio  slope_age_ratio  vessels_age_ratio  \n",
       "0          -0.692345       -0.341351         0.553834           2.501343  \n",
       "1          -0.692345        1.608507         0.958370          -0.691960  \n",
       "2          -0.692345       -1.172852         0.375535           1.249190  \n",
       "3          -0.692345        0.231957        -1.095430          -0.448627  \n",
       "4           1.118166       -0.760309         2.014610           2.285228  "
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled =pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled =pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>Rank_Sum</th>\n",
       "      <th>age_group</th>\n",
       "      <th>bp_category</th>\n",
       "      <th>cholesterol_age_ratio</th>\n",
       "      <th>heart_rate_reserve</th>\n",
       "      <th>angina_chest_pain</th>\n",
       "      <th>bp_to_hr_ratio</th>\n",
       "      <th>slope_age_ratio</th>\n",
       "      <th>vessels_age_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.435448</td>\n",
       "      <td>-1.000685</td>\n",
       "      <td>-0.452124</td>\n",
       "      <td>0.341500</td>\n",
       "      <td>-1.075714</td>\n",
       "      <td>1.006526</td>\n",
       "      <td>-1.228060</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>-1.006526</td>\n",
       "      <td>-0.907156</td>\n",
       "      <td>0.007523</td>\n",
       "      <td>1.393939</td>\n",
       "      <td>-0.450350</td>\n",
       "      <td>-0.216855</td>\n",
       "      <td>-1.502696</td>\n",
       "      <td>-0.572701</td>\n",
       "      <td>-0.214382</td>\n",
       "      <td>0.067142</td>\n",
       "      <td>-0.692345</td>\n",
       "      <td>-0.341351</td>\n",
       "      <td>0.553834</td>\n",
       "      <td>2.501343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.025949</td>\n",
       "      <td>0.999316</td>\n",
       "      <td>0.443539</td>\n",
       "      <td>1.630098</td>\n",
       "      <td>-1.474637</td>\n",
       "      <td>-0.993516</td>\n",
       "      <td>-0.005233</td>\n",
       "      <td>-0.850975</td>\n",
       "      <td>-1.006526</td>\n",
       "      <td>-1.300077</td>\n",
       "      <td>1.228338</td>\n",
       "      <td>-0.728579</td>\n",
       "      <td>-1.352596</td>\n",
       "      <td>-0.216855</td>\n",
       "      <td>0.133299</td>\n",
       "      <td>-0.572701</td>\n",
       "      <td>-1.194684</td>\n",
       "      <td>0.808153</td>\n",
       "      <td>-0.692345</td>\n",
       "      <td>1.608507</td>\n",
       "      <td>0.958370</td>\n",
       "      <td>-0.691960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.153548</td>\n",
       "      <td>0.999316</td>\n",
       "      <td>0.443539</td>\n",
       "      <td>-1.494754</td>\n",
       "      <td>-1.099180</td>\n",
       "      <td>1.006526</td>\n",
       "      <td>-1.228060</td>\n",
       "      <td>0.490591</td>\n",
       "      <td>-1.006526</td>\n",
       "      <td>-0.570367</td>\n",
       "      <td>0.007523</td>\n",
       "      <td>0.686433</td>\n",
       "      <td>-0.450350</td>\n",
       "      <td>-0.216855</td>\n",
       "      <td>-1.502696</td>\n",
       "      <td>1.626020</td>\n",
       "      <td>-0.437532</td>\n",
       "      <td>-0.056360</td>\n",
       "      <td>-0.692345</td>\n",
       "      <td>-1.172852</td>\n",
       "      <td>0.375535</td>\n",
       "      <td>1.249190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.524501</td>\n",
       "      <td>-1.000685</td>\n",
       "      <td>-1.347787</td>\n",
       "      <td>-1.108174</td>\n",
       "      <td>-0.285689</td>\n",
       "      <td>1.006526</td>\n",
       "      <td>1.217594</td>\n",
       "      <td>-1.271859</td>\n",
       "      <td>0.993516</td>\n",
       "      <td>1.001317</td>\n",
       "      <td>-1.213292</td>\n",
       "      <td>-0.021073</td>\n",
       "      <td>0.451895</td>\n",
       "      <td>-1.140675</td>\n",
       "      <td>0.951297</td>\n",
       "      <td>1.626020</td>\n",
       "      <td>-0.846515</td>\n",
       "      <td>0.659951</td>\n",
       "      <td>-0.692345</td>\n",
       "      <td>0.231957</td>\n",
       "      <td>-1.095430</td>\n",
       "      <td>-0.448627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.294498</td>\n",
       "      <td>0.999316</td>\n",
       "      <td>0.443539</td>\n",
       "      <td>-0.270585</td>\n",
       "      <td>0.598200</td>\n",
       "      <td>1.006526</td>\n",
       "      <td>-0.005233</td>\n",
       "      <td>0.779948</td>\n",
       "      <td>0.993516</td>\n",
       "      <td>-1.243945</td>\n",
       "      <td>1.228338</td>\n",
       "      <td>1.393939</td>\n",
       "      <td>-1.352596</td>\n",
       "      <td>-1.140675</td>\n",
       "      <td>-1.502696</td>\n",
       "      <td>0.160206</td>\n",
       "      <td>1.493142</td>\n",
       "      <td>-0.278664</td>\n",
       "      <td>1.118166</td>\n",
       "      <td>-0.760309</td>\n",
       "      <td>2.014610</td>\n",
       "      <td>2.285228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex        cp  trestbps      chol       fbs   restecg  \\\n",
       "0 -1.435448 -1.000685 -0.452124  0.341500 -1.075714  1.006526 -1.228060   \n",
       "1 -0.025949  0.999316  0.443539  1.630098 -1.474637 -0.993516 -0.005233   \n",
       "2 -1.153548  0.999316  0.443539 -1.494754 -1.099180  1.006526 -1.228060   \n",
       "3  1.524501 -1.000685 -1.347787 -1.108174 -0.285689  1.006526  1.217594   \n",
       "4 -1.294498  0.999316  0.443539 -0.270585  0.598200  1.006526 -0.005233   \n",
       "\n",
       "    thalach     exang   oldpeak     slope        ca      thal  Rank_Sum  \\\n",
       "0  0.464286 -1.006526 -0.907156  0.007523  1.393939 -0.450350 -0.216855   \n",
       "1 -0.850975 -1.006526 -1.300077  1.228338 -0.728579 -1.352596 -0.216855   \n",
       "2  0.490591 -1.006526 -0.570367  0.007523  0.686433 -0.450350 -0.216855   \n",
       "3 -1.271859  0.993516  1.001317 -1.213292 -0.021073  0.451895 -1.140675   \n",
       "4  0.779948  0.993516 -1.243945  1.228338  1.393939 -1.352596 -1.140675   \n",
       "\n",
       "   age_group  bp_category  cholesterol_age_ratio  heart_rate_reserve  \\\n",
       "0  -1.502696    -0.572701              -0.214382            0.067142   \n",
       "1   0.133299    -0.572701              -1.194684            0.808153   \n",
       "2  -1.502696     1.626020              -0.437532           -0.056360   \n",
       "3   0.951297     1.626020              -0.846515            0.659951   \n",
       "4  -1.502696     0.160206               1.493142           -0.278664   \n",
       "\n",
       "   angina_chest_pain  bp_to_hr_ratio  slope_age_ratio  vessels_age_ratio  \n",
       "0          -0.692345       -0.341351         0.553834           2.501343  \n",
       "1          -0.692345        1.608507         0.958370          -0.691960  \n",
       "2          -0.692345       -1.172852         0.375535           1.249190  \n",
       "3          -0.692345        0.231957        -1.095430          -0.448627  \n",
       "4           1.118166       -0.760309         2.014610           2.285228  "
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_index = X_train_scaled.index\n",
    "test_index = X_test_scaled.index \n",
    "\n",
    "pca = PCA()\n",
    "X_train = pca.fit_transform(X_train_scaled)\n",
    "X_test = pca.transform(X_test_scaled)\n",
    "\n",
    "X_train = pd.DataFrame(X_train_scaled, columns= X_train_scaled.columns, index=train_index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns= X_test_scaled.columns, index=test_index)\n",
    "\n",
    "X_train, y_train= smote.fit_resample(X_train, y_train)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rf classification report is \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.75      0.60       275\n",
      "           1       0.93      0.82      0.88      1186\n",
      "\n",
      "    accuracy                           0.81      1461\n",
      "   macro avg       0.72      0.79      0.74      1461\n",
      "weighted avg       0.85      0.81      0.82      1461\n",
      "\n",
      "\n",
      "The rf accuracy is \n",
      "0.81\n",
      "\n",
      "The lgb classification report is \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.56      0.51       275\n",
      "           1       0.89      0.86      0.87      1186\n",
      "\n",
      "    accuracy                           0.80      1461\n",
      "   macro avg       0.68      0.71      0.69      1461\n",
      "weighted avg       0.81      0.80      0.81      1461\n",
      "\n",
      "\n",
      "The lgb accuracy is \n",
      "0.801\n",
      "\n",
      "The xgb classification report is \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.51      0.50       275\n",
      "           1       0.89      0.88      0.88      1186\n",
      "\n",
      "    accuracy                           0.81      1461\n",
      "   macro avg       0.69      0.70      0.69      1461\n",
      "weighted avg       0.81      0.81      0.81      1461\n",
      "\n",
      "\n",
      "The xgb accuracy is \n",
      "0.81\n",
      "\n",
      "The cboost classification report is \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.60      0.54       275\n",
      "           1       0.90      0.86      0.88      1186\n",
      "\n",
      "    accuracy                           0.81      1461\n",
      "   macro avg       0.70      0.73      0.71      1461\n",
      "weighted avg       0.83      0.81      0.82      1461\n",
      "\n",
      "\n",
      "The cboost accuracy is \n",
      "0.81\n",
      "\n",
      "The lr classification report is \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.96      0.65       275\n",
      "           1       0.99      0.77      0.87      1186\n",
      "\n",
      "    accuracy                           0.81      1461\n",
      "   macro avg       0.74      0.87      0.76      1461\n",
      "weighted avg       0.90      0.81      0.83      1461\n",
      "\n",
      "\n",
      "The lr accuracy is \n",
      "0.808\n",
      "\n",
      "The GB classification report is \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.89      0.65       275\n",
      "           1       0.97      0.80      0.88      1186\n",
      "\n",
      "    accuracy                           0.82      1461\n",
      "   macro avg       0.74      0.84      0.76      1461\n",
      "weighted avg       0.88      0.82      0.83      1461\n",
      "\n",
      "\n",
      "The GB accuracy is \n",
      "0.819\n",
      "\n",
      "The mlp classification report is \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.60      0.54       275\n",
      "           1       0.90      0.86      0.88      1186\n",
      "\n",
      "    accuracy                           0.81      1461\n",
      "   macro avg       0.70      0.73      0.71      1461\n",
      "weighted avg       0.83      0.81      0.82      1461\n",
      "\n",
      "\n",
      "The mlp accuracy is \n",
      "0.81\n",
      "\n",
      "The svm classification report is \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.93      0.65       275\n",
      "           1       0.98      0.78      0.87      1186\n",
      "\n",
      "    accuracy                           0.81      1461\n",
      "   macro avg       0.74      0.86      0.76      1461\n",
      "weighted avg       0.89      0.81      0.83      1461\n",
      "\n",
      "\n",
      "The svm accuracy is \n",
      "0.809\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "models_names = {\n",
    "    'rf' : RandomForestClassifier(random_state=42,),\n",
    "    'lgb' : lgb.LGBMClassifier(random_state=42, verbose=0),\n",
    "    'xgb' : xgb.XGBClassifier(random_state=42,verbose=0),\n",
    "    'cboost' : cbt.CatBoostClassifier(random_state=42, verbose=0),\n",
    "    'lr' : LogisticRegression(random_state=42),\n",
    "    'GB' : GradientBoostingClassifier(random_state=42),\n",
    "    'mlp' : MLPClassifier(),\n",
    "    'svm' : svm.SVC(random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in models_names.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    prediction= model.predict(X_test)\n",
    "    score= accuracy_score(y_test, prediction)\n",
    "    cl_report= classification_report(y_test, prediction)\n",
    "    confusion_mat= confusion_matrix(y_test, prediction)\n",
    "    print(f\"The {name} classification report is \\n{cl_report}\\n\")\n",
    "    print(f\"The {name} accuracy is \\n{round(score,3)}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Move on with the Best Model (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Instantiate the GradientBoostingClassifier\n",
    "classifier = lgb.LGBMClassifier(random_state=42, verbose=0)\n",
    "\n",
    "# Fit the model\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importance_df = pd.DataFrame(classifier.feature_importances_, columns=['importance'])\n",
    "feature_importance_df['feature'] = X_train.columns\n",
    "\n",
    "# Plotting the top 50 feature importances\n",
    "plt.figure(figsize=(20, 12))\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=feature_importance_df.sort_values(by='importance', ascending=False).head(50))\n",
    "plt.title('LGBMClassifier Features Importance (Top 50)')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[shap values: https://www.datacamp.com/tutorial/introduction-to-shap-values-machine-learning-interpretability]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 Features:\n",
      " ['oldpeak', 'cholesterol_age_ratio', 'cp', 'Rank_Sum', 'bp_to_hr_ratio', 'chol', 'thalach', 'heart_rate_reserve', 'trestbps', 'thal', 'age', 'ca', 'vessels_age_ratio', 'slope_age_ratio', 'restecg']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "top_15_features = feature_importance_df.sort_values(by='importance', ascending=False).head(15)\n",
    "\n",
    "# Display only the feature names of the top 15 columns\n",
    "print(\"Top 15 Features:\\n\", top_15_features['feature'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train[['oldpeak', 'cholesterol_age_ratio', 'cp', 'Rank_Sum', \n",
    "'bp_to_hr_ratio', 'chol', 'thalach', 'heart_rate_reserve', \n",
    "'trestbps', 'thal', 'age', 'ca', 'vessels_age_ratio', \n",
    "'slope_age_ratio', 'restecg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test= test[['oldpeak', 'cholesterol_age_ratio', 'cp', 'Rank_Sum', \n",
    "'bp_to_hr_ratio', 'chol', 'thalach', 'heart_rate_reserve', \n",
    "'trestbps', 'thal', 'age', 'ca', 'vessels_age_ratio', \n",
    "'slope_age_ratio', 'restecg']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy()\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "\n",
    "def objective(trial):\n",
    "    fold_pred=[]\n",
    "    oof_pred = []\n",
    "\n",
    "\n",
    "    param = {}\n",
    "    param['objective'] = \"binary\"\n",
    "\n",
    "    param[\"learning_rate\"] = trial.suggest_float(\"learning_rate\", 1e-2, 0.30, log=True)\n",
    "    #param['reg_lambda'] = trial.suggest_loguniform(\"reg_lambda\", 1e-8, 100.0)\n",
    "    #param['reg_alpha'] = trial.suggest_loguniform(\"reg_alpha\", 1e-8, 100.0)\n",
    "    param['subsample'] = trial.suggest_float(\"subsample\", 0.1, 1.0)\n",
    "    param['colsample_bytree'] = trial.suggest_float(\"colsample_bytree\", 0.1, 1.0)\n",
    "    param['max_depth'] = trial.suggest_int(\"max_depth\", 20, 50)\n",
    "    param['scale_pos_weight'] = trial.suggest_int('scale_pos_weight', 6,10)\n",
    "    param['n_estimators'] = trial.suggest_int('n_estimators', 400,4000)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fold=StratifiedKFold(n_splits=8,shuffle=True, random_state=42) #15#5#10\n",
    "    i=1\n",
    "    for train_index, test_index in fold.split(X,y):\n",
    "\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        # m2 = CatBoostRegressor(**param)\n",
    "        m2 = lgb.LGBMClassifier(**param, verbose=0)\n",
    "\n",
    "        m2.fit(X_train,y_train,eval_set=[(X_train,y_train),(X_test, y_test)], callbacks=[log_evaluation(1200)])#erly100\n",
    "        preds=m2.predict(X_test)\n",
    "        oof_pred.append(f1_score(y_test,preds))\n",
    "\n",
    "    return np.mean(oof_pred) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best trial\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print(f\"Best trial value (Validation Loss): {best_trial.value}\")\n",
    "print(\"Best hyperparameters found:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "predictions = []\n",
    "scores = []\n",
    "i=0\n",
    "\n",
    "params = {'learning_rate': 0.02,\n",
    "'subsample': 0.8,\n",
    "'colsample_bytree': 0.1,\n",
    "'max_depth': 5,\n",
    "'scale_pos_weight': 6,\n",
    "'n_estimators': 500,\n",
    "'verbosity': -1\n",
    "          }\n",
    "\n",
    "fold=StratifiedKFold(n_splits=10,shuffle=True, random_state=1)\n",
    "\n",
    "for train_index, test_index in fold.split(train,y):\n",
    "    X_train, X_test = train.iloc[train_index], train.iloc[test_index]\n",
    "    Y_train, Y_test = y[train_index], y[test_index]\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    classifier2 = lgb.LGBMClassifier(**params, verbose=0)\n",
    "    classifier2.fit(X_train, Y_train)\n",
    "    \n",
    "    preds=classifier2.predict(X_test)\n",
    "    score = f1_score(Y_test,preds)\n",
    "    scores.append(score)\n",
    "    print(\"F1: \", score)\n",
    "    predictions.append(classifier2.predict(test))\n",
    "    i=i+1\n",
    "\n",
    "\n",
    "print(np.mean(scores))\n",
    "\n",
    "#Trial 652 finished with value: 0.9687548448537013 and parameters: {'learning_rate': 0.1805243125886494, 'subsample': 0.2128564969905326, 'colsample_bytree': 0.5046224462041669, 'max_depth': 13, 'scale_pos_weight': 6, 'n_estimators': 995}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random search Tuning Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters from Random Search:\n",
      "{'subsample': 0.8, 'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.02, 'colsample_bytree': 0.1}\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters from Random Search:\n",
      "{'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.03, 'colsample_bytree': 0.7000000000000001}\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters from Random Search:\n",
      "{'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.03, 'colsample_bytree': 0.7000000000000001}\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters from Random Search:\n",
      "{'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.03, 'colsample_bytree': 0.7000000000000001}\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters from Random Search:\n",
      "{'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.03, 'colsample_bytree': 0.7000000000000001}\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters from Random Search:\n",
      "{'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.03, 'colsample_bytree': 0.7000000000000001}\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters from Random Search:\n",
      "{'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.03, 'colsample_bytree': 0.7000000000000001}\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters from Random Search:\n",
      "{'subsample': 0.8, 'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.02, 'colsample_bytree': 0.1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from lightgbm import LGBMClassifier\n",
    "X = train.copy()\n",
    "\n",
    "# Step 1: Define the parameter grid for Random Search\n",
    "param_dist = {\n",
    "    'learning_rate': np.linspace(0.01, 0.2, 20),\n",
    "    'n_estimators': np.arange(100, 1001, 50),\n",
    "    'max_depth': np.arange(3, 15, 1),\n",
    "    'subsample': np.linspace(0.1, 1.0, 10),\n",
    "    'colsample_bytree': np.linspace(0.1, 1.0, 10)\n",
    "}\n",
    "\n",
    "fold=StratifiedKFold(n_splits=8,shuffle=True, random_state=42) #15#5#10\n",
    "i=1\n",
    "for train_index, test_index in fold.split(X,y):\n",
    "\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    # m2 = CatBoostRegressor(**param)\n",
    "    random_search = RandomizedSearchCV(\n",
    "    lgb.LGBMClassifier(verbose=0),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=100,  # Number of random samples\n",
    "    cv=5,        # Cross-validation\n",
    "    random_state=42,\n",
    "    n_jobs=-1    # Use all available cores\n",
    ")\n",
    "\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best parameters from Random Search\n",
    "    best_params = random_search.best_params_\n",
    "    print(\"Best parameters from Random Search:\")\n",
    "    print(best_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions with RS best parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.8974358974358975\n",
      "F1:  0.8966037735849056\n",
      "F1:  0.8966037735849056\n",
      "F1:  0.8972809667673716\n",
      "F1:  0.8972809667673716\n",
      "F1:  0.8972809667673716\n",
      "F1:  0.8972809667673716\n",
      "F1:  0.8972809667673716\n",
      "F1:  0.8972809667673716\n",
      "F1:  0.8972809667673716\n",
      "0.897161021197731\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "predictions_rs = []\n",
    "scores = []\n",
    "i=0\n",
    "\n",
    "params = {'learning_rate': 0.02,\n",
    "'subsample': 0.8,\n",
    "'colsample_bytree': 0.1,\n",
    "'max_depth': 5,\n",
    "'scale_pos_weight': 6,\n",
    "'n_estimators': 500,\n",
    "'verbosity': -1\n",
    "          }\n",
    "\n",
    "fold=StratifiedKFold(n_splits=10,shuffle=True, random_state=1)\n",
    "\n",
    "for train_index, test_index in fold.split(train,y):\n",
    "    X_train, X_test = train.iloc[train_index], train.iloc[test_index]\n",
    "    Y_train, Y_test = y[train_index], y[test_index]\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    classifier2 = lgb.LGBMClassifier(**params, verbose=0)\n",
    "    classifier2.fit(X_train, Y_train)\n",
    "    \n",
    "    preds=classifier2.predict(X_test)\n",
    "    score = f1_score(Y_test,preds)\n",
    "    scores.append(score)\n",
    "    print(\"F1: \", score)\n",
    "    predictions_rs.append(classifier2.predict(test))\n",
    "    i=i+1\n",
    "\n",
    "\n",
    "print(np.mean(scores))\n",
    "\n",
    "#Trial 652 finished with value: 0.9687548448537013 and parameters: {'learning_rate': 0.1805243125886494, 'subsample': 0.2128564969905326, 'colsample_bytree': 0.5046224462041669, 'max_depth': 13, 'scale_pos_weight': 6, 'n_estimators': 995}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Aggregating predictions (e.g., majority voting if multiple predictions)\n",
    "final_predictions = np.mean(predictions_rs, axis=0)\n",
    "final_predictions = np.where(final_predictions > 0.5, 1, 0)\n",
    "\n",
    "# Preparing for submission (if needed)\n",
    "test_rs=pd.read_csv('Test Dataset.csv')\n",
    "sub_rs = pd.DataFrame({'ID': test_rs['id'], 'target': final_predictions})\n",
    "sub_rs.to_csv('win_rs.csv', index=False)\n",
    "print(\"Submission file created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Randomsearch and Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy()\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "\n",
    "def objective(trial):\n",
    "    fold_pred=[]\n",
    "    oof_pred = []\n",
    "\n",
    "\n",
    "    param = {}\n",
    "    param['objective'] = \"binary\"\n",
    "\n",
    "    param[\"learning_rate\"] = trial.suggest_float('learning_rate', max(1e-3, best_params['learning_rate'] * 0.5), \n",
    "            min(1.0, best_params['learning_rate'] * 1.5))\n",
    "    #param['reg_lambda'] = trial.suggest_loguniform(\"reg_lambda\", 1e-8, 100.0)\n",
    "    #param['reg_alpha'] = trial.suggest_loguniform(\"reg_alpha\", 1e-8, 100.0)\n",
    "    param['subsample'] = trial.suggest_float('subsample', max(0.1, best_params['subsample'] * 0.5), \n",
    "            min(1.0, best_params['subsample'] * 1.5))\n",
    "    param['colsample_bytree'] = trial.suggest_float('colsample_bytree', max(0.1, best_params['colsample_bytree'] * 0.5), \n",
    "            min(1.0, best_params['colsample_bytree'] * 1.5))\n",
    "    param['max_depth'] = trial.suggest_int('max_depth', max(3, best_params['max_depth'] - 2), \n",
    "            best_params['max_depth'] + 2)\n",
    "    param['scale_pos_weight'] = trial.suggest_int('scale_pos_weight', 6,10)\n",
    "    param['n_estimators'] = trial.suggest_int('n_estimators', max(100, best_params['n_estimators'] - 50), \n",
    "            best_params['n_estimators'] + 50)\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fold=StratifiedKFold(n_splits=8,shuffle=True, random_state=42) #15#5#10\n",
    "    i=1\n",
    "    for train_index, test_index in fold.split(X,y):\n",
    "\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        # m2 = CatBoostRegressor(**param)\n",
    "        m2 = lgb.LGBMClassifier(**param, verbose=-1)\n",
    "\n",
    "        m2.fit(X_train,y_train,eval_set=[(X_train,y_train),(X_test, y_test)], callbacks=[log_evaluation(1200)])#erly100\n",
    "        preds=m2.predict(X_test)\n",
    "        oof_pred.append(f1_score(y_test,preds))\n",
    "\n",
    "    return np.mean(oof_pred) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-24 16:11:25,347] A new study created in memory with name: no-name-13db8885-fbec-4445-9c6a-ba85999b9a7e\n",
      "[I 2024-09-24 16:11:36,281] Trial 0 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.029628267510170232, 'subsample': 0.5525720809882995, 'colsample_bytree': 0.11651471845711506, 'max_depth': 5, 'scale_pos_weight': 6, 'n_estimators': 545}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:11:50,860] Trial 1 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.013832031868981114, 'subsample': 0.8078180221524272, 'colsample_bytree': 0.11178844539620642, 'max_depth': 6, 'scale_pos_weight': 10, 'n_estimators': 496}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:11:55,579] Trial 2 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.019329517010623975, 'subsample': 0.7238226235353034, 'colsample_bytree': 0.10428291986253563, 'max_depth': 3, 'scale_pos_weight': 6, 'n_estimators': 527}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:12:12,075] Trial 3 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.014918095756147914, 'subsample': 0.8224608202533985, 'colsample_bytree': 0.13936450214286292, 'max_depth': 7, 'scale_pos_weight': 9, 'n_estimators': 544}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:12:18,847] Trial 4 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.014744825679398957, 'subsample': 0.8621280822500621, 'colsample_bytree': 0.13683268820367434, 'max_depth': 3, 'scale_pos_weight': 6, 'n_estimators': 457}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:12:27,487] Trial 5 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.02814574449842277, 'subsample': 0.561410876733772, 'colsample_bytree': 0.13481525155861565, 'max_depth': 5, 'scale_pos_weight': 10, 'n_estimators': 473}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:12:36,500] Trial 6 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.029355233723657524, 'subsample': 0.5580467995768872, 'colsample_bytree': 0.1485175754322342, 'max_depth': 3, 'scale_pos_weight': 8, 'n_estimators': 466}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:12:50,283] Trial 7 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.013364882355569183, 'subsample': 0.782449477654318, 'colsample_bytree': 0.1173484642440644, 'max_depth': 4, 'scale_pos_weight': 7, 'n_estimators': 535}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:13:04,954] Trial 8 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.026764134967578464, 'subsample': 0.6001540143717983, 'colsample_bytree': 0.1222976010520125, 'max_depth': 3, 'scale_pos_weight': 9, 'n_estimators': 535}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:13:27,667] Trial 9 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.02082967421178892, 'subsample': 0.6081857436026896, 'colsample_bytree': 0.10218424793898251, 'max_depth': 7, 'scale_pos_weight': 6, 'n_estimators': 479}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:13:51,011] Trial 10 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.02282827399546359, 'subsample': 0.42862914053287693, 'colsample_bytree': 0.12446965526842471, 'max_depth': 5, 'scale_pos_weight': 7, 'n_estimators': 514}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:14:06,412] Trial 11 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.010152330641913405, 'subsample': 0.9555097525978014, 'colsample_bytree': 0.11092073299529585, 'max_depth': 6, 'scale_pos_weight': 10, 'n_estimators': 493}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:14:19,490] Trial 12 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.02458596213109912, 'subsample': 0.44618527979378225, 'colsample_bytree': 0.11333810324651872, 'max_depth': 6, 'scale_pos_weight': 8, 'n_estimators': 504}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:14:29,756] Trial 13 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.017585256477111077, 'subsample': 0.6811769900011868, 'colsample_bytree': 0.10919774468101227, 'max_depth': 6, 'scale_pos_weight': 9, 'n_estimators': 492}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:14:38,976] Trial 14 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.0111534605195425, 'subsample': 0.9862408233292137, 'colsample_bytree': 0.11771683003292328, 'max_depth': 4, 'scale_pos_weight': 7, 'n_estimators': 514}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:14:48,641] Trial 15 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.017270250083659167, 'subsample': 0.699618783929955, 'colsample_bytree': 0.10709385679700331, 'max_depth': 5, 'scale_pos_weight': 10, 'n_estimators': 518}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:15:00,985] Trial 16 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.025464823385998654, 'subsample': 0.8916164459648854, 'colsample_bytree': 0.11878938453786464, 'max_depth': 6, 'scale_pos_weight': 8, 'n_estimators': 550}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:15:09,268] Trial 17 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.0210228516632212, 'subsample': 0.5010418395902386, 'colsample_bytree': 0.13165862128188666, 'max_depth': 4, 'scale_pos_weight': 9, 'n_estimators': 485}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:15:19,815] Trial 18 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.0237230537679467, 'subsample': 0.7792665721073293, 'colsample_bytree': 0.12892118582471185, 'max_depth': 7, 'scale_pos_weight': 7, 'n_estimators': 501}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:15:27,253] Trial 19 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.012533393084293801, 'subsample': 0.651992004453227, 'colsample_bytree': 0.11205684984093099, 'max_depth': 6, 'scale_pos_weight': 6, 'n_estimators': 509}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:15:38,548] Trial 20 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.016695813176945257, 'subsample': 0.49851506509561383, 'colsample_bytree': 0.10113769903924588, 'max_depth': 5, 'scale_pos_weight': 8, 'n_estimators': 528}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:15:50,840] Trial 21 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.018865418013370844, 'subsample': 0.7553801088202282, 'colsample_bytree': 0.10556601664186364, 'max_depth': 4, 'scale_pos_weight': 6, 'n_estimators': 525}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:16:01,996] Trial 22 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.022390168930188716, 'subsample': 0.735091191228283, 'colsample_bytree': 0.11553548765436186, 'max_depth': 4, 'scale_pos_weight': 6, 'n_estimators': 543}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:16:09,895] Trial 23 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.01925431444387898, 'subsample': 0.90803803802583, 'colsample_bytree': 0.10644505612404445, 'max_depth': 3, 'scale_pos_weight': 7, 'n_estimators': 525}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:16:21,943] Trial 24 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.015205652155629582, 'subsample': 0.8300815257032637, 'colsample_bytree': 0.12191182909296991, 'max_depth': 6, 'scale_pos_weight': 6, 'n_estimators': 538}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:16:31,966] Trial 25 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.02738322824558696, 'subsample': 0.7248236968767492, 'colsample_bytree': 0.10349818102155035, 'max_depth': 5, 'scale_pos_weight': 7, 'n_estimators': 492}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:16:45,039] Trial 26 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.012493864150105005, 'subsample': 0.6534487205444189, 'colsample_bytree': 0.10029288454374126, 'max_depth': 7, 'scale_pos_weight': 6, 'n_estimators': 549}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:16:54,945] Trial 27 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.021728233346660877, 'subsample': 0.8149090921560509, 'colsample_bytree': 0.11358202178808939, 'max_depth': 5, 'scale_pos_weight': 10, 'n_estimators': 530}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:17:07,221] Trial 28 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.029642508907012838, 'subsample': 0.6386397271259634, 'colsample_bytree': 0.10974485610540123, 'max_depth': 6, 'scale_pos_weight': 7, 'n_estimators': 519}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:17:19,360] Trial 29 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.019716692888498838, 'subsample': 0.8155736729527445, 'colsample_bytree': 0.12065913144865008, 'max_depth': 7, 'scale_pos_weight': 8, 'n_estimators': 543}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:17:30,195] Trial 30 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.015629984883005862, 'subsample': 0.5375801969102079, 'colsample_bytree': 0.12787402181277044, 'max_depth': 4, 'scale_pos_weight': 9, 'n_estimators': 508}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:17:46,759] Trial 31 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.013761157575978502, 'subsample': 0.8648254542736168, 'colsample_bytree': 0.14374465054362917, 'max_depth': 7, 'scale_pos_weight': 9, 'n_estimators': 543}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:17:58,625] Trial 32 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.0164518506337207, 'subsample': 0.8523326610977622, 'colsample_bytree': 0.1381441087354605, 'max_depth': 7, 'scale_pos_weight': 10, 'n_estimators': 538}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:18:04,090] Trial 33 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.01425132177401215, 'subsample': 0.8963752002535565, 'colsample_bytree': 0.14075116058840675, 'max_depth': 3, 'scale_pos_weight': 9, 'n_estimators': 460}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:18:15,592] Trial 34 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.012042987281837118, 'subsample': 0.7761117595295374, 'colsample_bytree': 0.13223666390380723, 'max_depth': 6, 'scale_pos_weight': 10, 'n_estimators': 533}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:18:22,148] Trial 35 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.01838139941141814, 'subsample': 0.724702254567706, 'colsample_bytree': 0.14867654257475305, 'max_depth': 3, 'scale_pos_weight': 10, 'n_estimators': 546}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:18:38,597] Trial 36 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.015511100946749456, 'subsample': 0.5982348156110584, 'colsample_bytree': 0.14494402653742117, 'max_depth': 7, 'scale_pos_weight': 9, 'n_estimators': 452}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:18:45,542] Trial 37 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.014618306858513057, 'subsample': 0.9378343945711723, 'colsample_bytree': 0.11535763282344838, 'max_depth': 5, 'scale_pos_weight': 6, 'n_estimators': 472}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:18:54,143] Trial 38 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.026221313574099424, 'subsample': 0.7984482680323355, 'colsample_bytree': 0.1047733500319946, 'max_depth': 7, 'scale_pos_weight': 8, 'n_estimators': 538}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:18:59,995] Trial 39 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.01005662092589061, 'subsample': 0.7543914846003346, 'colsample_bytree': 0.12518960090703915, 'max_depth': 3, 'scale_pos_weight': 10, 'n_estimators': 497}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:19:15,469] Trial 40 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.028425803136784153, 'subsample': 0.8639769453440328, 'colsample_bytree': 0.10812919409483499, 'max_depth': 6, 'scale_pos_weight': 6, 'n_estimators': 480}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:19:20,564] Trial 41 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.013396928724842517, 'subsample': 0.8431498884330831, 'colsample_bytree': 0.13626353940320066, 'max_depth': 3, 'scale_pos_weight': 6, 'n_estimators': 465}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:19:28,159] Trial 42 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.01820225257960654, 'subsample': 0.6929847608037227, 'colsample_bytree': 0.13954577231976914, 'max_depth': 3, 'scale_pos_weight': 6, 'n_estimators': 520}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:19:33,080] Trial 43 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.011146035341071094, 'subsample': 0.7904903567827302, 'colsample_bytree': 0.14239320417939222, 'max_depth': 4, 'scale_pos_weight': 7, 'n_estimators': 454}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:19:37,188] Trial 44 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.0163312403876047, 'subsample': 0.5781159581390228, 'colsample_bytree': 0.14575004874908537, 'max_depth': 3, 'scale_pos_weight': 6, 'n_estimators': 476}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:19:42,592] Trial 45 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.02035623777820212, 'subsample': 0.9236241141818031, 'colsample_bytree': 0.13418355628716705, 'max_depth': 4, 'scale_pos_weight': 9, 'n_estimators': 534}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:19:47,885] Trial 46 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.01461573118626088, 'subsample': 0.9732976064435246, 'colsample_bytree': 0.12514238126770172, 'max_depth': 5, 'scale_pos_weight': 7, 'n_estimators': 467}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:19:54,132] Trial 47 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.023554506212251573, 'subsample': 0.4078961947373747, 'colsample_bytree': 0.1193175698579791, 'max_depth': 6, 'scale_pos_weight': 6, 'n_estimators': 485}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:19:58,515] Trial 48 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.017412774434511495, 'subsample': 0.87270383822377, 'colsample_bytree': 0.11129895551027906, 'max_depth': 4, 'scale_pos_weight': 8, 'n_estimators': 512}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:20:02,502] Trial 49 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.024766966051181116, 'subsample': 0.46414941829246065, 'colsample_bytree': 0.11638788614511696, 'max_depth': 3, 'scale_pos_weight': 9, 'n_estimators': 550}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:20:10,594] Trial 50 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.01093571276116486, 'subsample': 0.7610563062094645, 'colsample_bytree': 0.10301634586842548, 'max_depth': 6, 'scale_pos_weight': 7, 'n_estimators': 524}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:20:15,840] Trial 51 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.029446233408539916, 'subsample': 0.5447888465555992, 'colsample_bytree': 0.13645696559547407, 'max_depth': 5, 'scale_pos_weight': 10, 'n_estimators': 461}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:20:21,574] Trial 52 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.028505459378063355, 'subsample': 0.519186034011222, 'colsample_bytree': 0.13358673247893924, 'max_depth': 5, 'scale_pos_weight': 10, 'n_estimators': 486}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:20:27,144] Trial 53 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.02818080351134527, 'subsample': 0.6055395308641646, 'colsample_bytree': 0.12790558656554993, 'max_depth': 5, 'scale_pos_weight': 10, 'n_estimators': 503}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:20:33,783] Trial 54 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.026912277385314494, 'subsample': 0.6665723891945506, 'colsample_bytree': 0.11350792911268336, 'max_depth': 6, 'scale_pos_weight': 10, 'n_estimators': 457}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:20:39,106] Trial 55 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.012756610482416948, 'subsample': 0.5633173056026306, 'colsample_bytree': 0.1300134459105222, 'max_depth': 5, 'scale_pos_weight': 6, 'n_estimators': 470}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:20:43,864] Trial 56 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.021556791115485686, 'subsample': 0.4651651673227366, 'colsample_bytree': 0.13680306515699003, 'max_depth': 4, 'scale_pos_weight': 9, 'n_estimators': 488}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:20:50,295] Trial 57 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.025442318853411135, 'subsample': 0.62444907104158, 'colsample_bytree': 0.1230989865415781, 'max_depth': 6, 'scale_pos_weight': 6, 'n_estimators': 480}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:20:55,003] Trial 58 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.027592230329705286, 'subsample': 0.8315963789487771, 'colsample_bytree': 0.14684512396646118, 'max_depth': 4, 'scale_pos_weight': 10, 'n_estimators': 540}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:21:00,475] Trial 59 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.011966078370613215, 'subsample': 0.7196391533910199, 'colsample_bytree': 0.10941494977282515, 'max_depth': 5, 'scale_pos_weight': 8, 'n_estimators': 450}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:21:08,418] Trial 60 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.029066951802049237, 'subsample': 0.8161772769444365, 'colsample_bytree': 0.1414969501031555, 'max_depth': 7, 'scale_pos_weight': 9, 'n_estimators': 529}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:21:11,763] Trial 61 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.029578111189165677, 'subsample': 0.48645426649336837, 'colsample_bytree': 0.1480524217368787, 'max_depth': 3, 'scale_pos_weight': 6, 'n_estimators': 462}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:21:15,129] Trial 62 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.028874140390331572, 'subsample': 0.5807861723696595, 'colsample_bytree': 0.14339767062817574, 'max_depth': 3, 'scale_pos_weight': 8, 'n_estimators': 475}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:21:18,562] Trial 63 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.016898306359690706, 'subsample': 0.5336372833678034, 'colsample_bytree': 0.1499048227463102, 'max_depth': 3, 'scale_pos_weight': 7, 'n_estimators': 456}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:21:22,466] Trial 64 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.02781682447515671, 'subsample': 0.6276836651886766, 'colsample_bytree': 0.13869564936737638, 'max_depth': 3, 'scale_pos_weight': 10, 'n_estimators': 546}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:21:26,432] Trial 65 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.026845171484367946, 'subsample': 0.56052643073142, 'colsample_bytree': 0.1344814549492142, 'max_depth': 4, 'scale_pos_weight': 9, 'n_estimators': 458}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:21:30,264] Trial 66 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.029842597393436643, 'subsample': 0.5090128458190926, 'colsample_bytree': 0.13121619222824982, 'max_depth': 3, 'scale_pos_weight': 6, 'n_estimators': 496}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:21:36,795] Trial 67 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.015834797124380497, 'subsample': 0.8886517658502249, 'colsample_bytree': 0.10664234451751733, 'max_depth': 7, 'scale_pos_weight': 7, 'n_estimators': 464}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:21:42,258] Trial 68 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.013917159762989875, 'subsample': 0.7435004775918053, 'colsample_bytree': 0.11726135481633562, 'max_depth': 5, 'scale_pos_weight': 10, 'n_estimators': 470}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:21:45,602] Trial 69 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.0259642830074005, 'subsample': 0.8058305550563711, 'colsample_bytree': 0.10470035809813022, 'max_depth': 3, 'scale_pos_weight': 6, 'n_estimators': 468}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:21:53,962] Trial 70 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.015036138294366638, 'subsample': 0.7104723123704383, 'colsample_bytree': 0.14017681515285468, 'max_depth': 6, 'scale_pos_weight': 9, 'n_estimators': 531}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:21:59,258] Trial 71 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.013309243894287587, 'subsample': 0.8401350662871796, 'colsample_bytree': 0.11261486141114152, 'max_depth': 4, 'scale_pos_weight': 8, 'n_estimators': 541}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:22:03,220] Trial 72 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.012181926217688252, 'subsample': 0.6866788673037116, 'colsample_bytree': 0.12007832377580033, 'max_depth': 3, 'scale_pos_weight': 7, 'n_estimators': 535}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:22:08,754] Trial 73 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.012884863777437878, 'subsample': 0.7843211824740999, 'colsample_bytree': 0.11500530573574626, 'max_depth': 5, 'scale_pos_weight': 8, 'n_estimators': 506}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:22:13,513] Trial 74 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.01414692959535713, 'subsample': 0.7785540752255692, 'colsample_bytree': 0.1185067987363585, 'max_depth': 4, 'scale_pos_weight': 6, 'n_estimators': 547}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:22:17,324] Trial 75 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.02238269270176966, 'subsample': 0.7641246830265013, 'colsample_bytree': 0.1268301623493168, 'max_depth': 3, 'scale_pos_weight': 7, 'n_estimators': 537}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:22:22,079] Trial 76 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.01466747814527219, 'subsample': 0.6701018162528577, 'colsample_bytree': 0.12194656422328408, 'max_depth': 4, 'scale_pos_weight': 6, 'n_estimators': 544}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:22:28,008] Trial 77 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.018009011544266162, 'subsample': 0.7371818828756748, 'colsample_bytree': 0.10753146540524311, 'max_depth': 5, 'scale_pos_weight': 6, 'n_estimators': 515}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:22:32,707] Trial 78 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.018909672548000075, 'subsample': 0.8572725113266197, 'colsample_bytree': 0.11116472217697226, 'max_depth': 3, 'scale_pos_weight': 7, 'n_estimators': 541}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:22:39,248] Trial 79 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.016068778175942534, 'subsample': 0.8804445610757333, 'colsample_bytree': 0.10030832277006313, 'max_depth': 6, 'scale_pos_weight': 8, 'n_estimators': 525}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:22:46,198] Trial 80 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.013373754042540912, 'subsample': 0.9122067958237335, 'colsample_bytree': 0.1234842111227899, 'max_depth': 5, 'scale_pos_weight': 6, 'n_estimators': 548}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:22:49,935] Trial 81 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.02878909689868715, 'subsample': 0.5916356941305746, 'colsample_bytree': 0.12099323892072365, 'max_depth': 3, 'scale_pos_weight': 10, 'n_estimators': 522}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:22:54,134] Trial 82 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.029964839769780167, 'subsample': 0.5603277916720766, 'colsample_bytree': 0.11732524521400338, 'max_depth': 3, 'scale_pos_weight': 9, 'n_estimators': 533}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:22:58,793] Trial 83 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.027949477693623853, 'subsample': 0.6201127808484028, 'colsample_bytree': 0.11462594505139134, 'max_depth': 3, 'scale_pos_weight': 9, 'n_estimators': 537}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:23:02,867] Trial 84 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.02704469012298779, 'subsample': 0.8207441976180783, 'colsample_bytree': 0.1351118160393502, 'max_depth': 3, 'scale_pos_weight': 8, 'n_estimators': 544}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:23:06,736] Trial 85 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.011527992725015654, 'subsample': 0.5374595761844103, 'colsample_bytree': 0.12623257755716114, 'max_depth': 3, 'scale_pos_weight': 10, 'n_estimators': 531}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:23:11,051] Trial 86 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.015229952627481808, 'subsample': 0.8014318364594203, 'colsample_bytree': 0.11859163070387416, 'max_depth': 4, 'scale_pos_weight': 9, 'n_estimators': 499}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:23:17,911] Trial 87 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.02919506469772291, 'subsample': 0.5213148868612528, 'colsample_bytree': 0.14503620418319993, 'max_depth': 7, 'scale_pos_weight': 7, 'n_estimators': 528}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:23:21,375] Trial 88 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.0238040241443371, 'subsample': 0.6460040575704462, 'colsample_bytree': 0.13286202525247434, 'max_depth': 3, 'scale_pos_weight': 10, 'n_estimators': 477}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:23:28,758] Trial 89 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.026299765389869285, 'subsample': 0.4865731760720371, 'colsample_bytree': 0.13787627236725636, 'max_depth': 6, 'scale_pos_weight': 6, 'n_estimators': 540}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:23:34,315] Trial 90 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.02088764299673449, 'subsample': 0.5792575287649634, 'colsample_bytree': 0.11020910536352015, 'max_depth': 4, 'scale_pos_weight': 6, 'n_estimators': 517}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:23:40,557] Trial 91 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.019367517046923986, 'subsample': 0.6083153656250244, 'colsample_bytree': 0.10258987023074478, 'max_depth': 7, 'scale_pos_weight': 6, 'n_estimators': 473}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:23:47,199] Trial 92 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.02517471385697021, 'subsample': 0.5589245712974011, 'colsample_bytree': 0.10148021123119948, 'max_depth': 7, 'scale_pos_weight': 6, 'n_estimators': 490}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:23:53,629] Trial 93 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.010564980900042157, 'subsample': 0.70567360024576, 'colsample_bytree': 0.10413836825839226, 'max_depth': 7, 'scale_pos_weight': 6, 'n_estimators': 478}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:24:01,490] Trial 94 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.016966399350009542, 'subsample': 0.5467738381048455, 'colsample_bytree': 0.11639595546212897, 'max_depth': 7, 'scale_pos_weight': 6, 'n_estimators': 482}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:24:07,641] Trial 95 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.02013500248602171, 'subsample': 0.5914990408537587, 'colsample_bytree': 0.12392145300707887, 'max_depth': 5, 'scale_pos_weight': 7, 'n_estimators': 466}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:24:13,866] Trial 96 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.028461034642928214, 'subsample': 0.8406485230506834, 'colsample_bytree': 0.10553420290113708, 'max_depth': 7, 'scale_pos_weight': 8, 'n_estimators': 462}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:24:17,360] Trial 97 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.023258402608870923, 'subsample': 0.7705356273056391, 'colsample_bytree': 0.1411186387299357, 'max_depth': 3, 'scale_pos_weight': 10, 'n_estimators': 459}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:24:24,147] Trial 98 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.014356958225664228, 'subsample': 0.7498552570207444, 'colsample_bytree': 0.10877990137855692, 'max_depth': 6, 'scale_pos_weight': 6, 'n_estimators': 455}. Best is trial 0 with value: 0.8971609141909.\n",
      "[I 2024-09-24 16:24:30,706] Trial 99 finished with value: 0.8971609141909 and parameters: {'learning_rate': 0.027361211860054285, 'subsample': 0.7915601183934952, 'colsample_bytree': 0.13095757335108538, 'max_depth': 5, 'scale_pos_weight': 9, 'n_estimators': 511}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial value (Validation Loss): 0.8971609141909\n",
      "Best hyperparameters found:\n",
      "learning_rate: 0.029628267510170232\n",
      "subsample: 0.5525720809882995\n",
      "colsample_bytree: 0.11651471845711506\n",
      "max_depth: 5\n",
      "scale_pos_weight: 6\n",
      "n_estimators: 545\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the best trial\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print(f\"Best trial value (Validation Loss): {best_trial.value}\")\n",
    "print(\"Best hyperparameters found:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions with the combination of RS and Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.8974358974358975\n",
      "F1:  0.8966037735849056\n",
      "F1:  0.8966037735849056\n",
      "F1:  0.8972809667673716\n",
      "F1:  0.8972809667673716\n",
      "F1:  0.8972809667673716\n",
      "F1:  0.8972809667673716\n",
      "F1:  0.8972809667673716\n",
      "F1:  0.8972809667673716\n",
      "F1:  0.8972809667673716\n",
      "0.897161021197731\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "predictions_rsop = []\n",
    "scores = []\n",
    "i=0\n",
    "\n",
    "params = {'learning_rate': 0.029628267510170232,\n",
    "'subsample': 0.5525720809882995,\n",
    "'colsample_bytree': 0.11651471845711506,\n",
    "'max_depth': 5,\n",
    "'scale_pos_weight': 6,\n",
    "'n_estimators': 545\n",
    "          }\n",
    "\n",
    "fold=StratifiedKFold(n_splits=10,shuffle=True, random_state=1)\n",
    "\n",
    "for train_index, test_index in fold.split(train,y):\n",
    "    X_train, X_test = train.iloc[train_index], train.iloc[test_index]\n",
    "    Y_train, Y_test = y[train_index], y[test_index]\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    classifier2 = lgb.LGBMClassifier(**params, verbose=-1)\n",
    "    classifier2.fit(X_train, Y_train)\n",
    "    \n",
    "    preds=classifier2.predict(X_test)\n",
    "    score = f1_score(Y_test,preds)\n",
    "    scores.append(score)\n",
    "    print(\"F1: \", score)\n",
    "    predictions_rsop.append(classifier2.predict(test))\n",
    "    i=i+1\n",
    "\n",
    "\n",
    "print(np.mean(scores))\n",
    "\n",
    "#Trial 652 finished with value: 0.9687548448537013 and parameters: {'learning_rate': 0.1805243125886494, 'subsample': 0.2128564969905326, 'colsample_bytree': 0.5046224462041669, 'max_depth': 13, 'scale_pos_weight': 6, 'n_estimators': 995}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Aggregating predictions (e.g., majority voting if multiple predictions)\n",
    "final_predictions = np.mean(predictions_rsop, axis=0)\n",
    "final_predictions = np.where(final_predictions > 0.5, 1, 0)\n",
    "\n",
    "# Preparing for submission (if needed)\n",
    "testdata=pd.read_csv('Test Dataset.csv')\n",
    "sub_rsop = pd.DataFrame({'ID': testdata['id'], 'target': final_predictions})\n",
    "sub_rsop.to_csv('win_rsop.csv', index=False)\n",
    "print(\"Submission file created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import f1_score\n",
    "import tensorflow as tf\n",
    "\n",
    "def objective(trial):\n",
    "    fold_pred = []\n",
    "    oof_pred = []\n",
    "\n",
    "    # Hyperparameter search space\n",
    "    units1 = trial.suggest_int(\"units1\", 32, 128)\n",
    "    units2 = trial.suggest_int(\"units2\", 32, 128)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
    "    activation1 = trial.suggest_categorical(\"activation1\", [\"relu\", \"tanh\", \"sigmoid\"])\n",
    "    activation2 = trial.suggest_categorical(\"activation2\", [\"relu\", \"tanh\", \"sigmoid\"])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 16, 64)\n",
    "    epochs = trial.suggest_int(\"epochs\", 10, 50)\n",
    "\n",
    "    fold = StratifiedKFold(n_splits=8, shuffle=True, random_state=42)  # Adjust n_splits as needed\n",
    "\n",
    "    for train_index, test_index in fold.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Create the neural network model\n",
    "        model = Sequential([\n",
    "            Dense(units1, activation=activation1, input_shape=(X_train.shape[1],)),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(units2, activation=activation2),\n",
    "            Dense(1, activation='sigmoid')  # For binary classification\n",
    "        ])\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "                      loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Train the model with evaluation set\n",
    "        model.fit(X_train, y_train, \n",
    "                  validation_data=(X_test, y_test),  # Use test set as validation set\n",
    "                  epochs=epochs, \n",
    "                  batch_size=batch_size, \n",
    "                  verbose=0)  # Set verbose=0 to silence output\n",
    "        \n",
    "        preds = (model.predict(X_test) > 0.5).astype(\"int32\")  # Convert probabilities to binary predictions\n",
    "        fold_pred.append(f1_score(y_test, preds))\n",
    "\n",
    "    return np.mean(fold_pred)  # Return the average F1 score over all folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 01:23:52,742] A new study created in memory with name: no-name-8ddddfde-4e46-4dd0-a10b-9a1db99978e8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 1s 11ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 01:28:45,429] Trial 0 finished with value: 0.8971609141909 and parameters: {'units1': 50, 'units2': 75, 'dropout_rate': 0.23212026912017683, 'learning_rate': 0.000351999395296267, 'activation1': 'tanh', 'activation2': 'sigmoid', 'batch_size': 19, 'epochs': 31}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 01:31:18,335] Trial 1 finished with value: 0.8971609141909 and parameters: {'units1': 107, 'units2': 43, 'dropout_rate': 0.35558933226416234, 'learning_rate': 7.828059823799994e-05, 'activation1': 'sigmoid', 'activation2': 'tanh', 'batch_size': 42, 'epochs': 36}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 01:35:16,307] Trial 2 finished with value: 0.8971609141909 and parameters: {'units1': 108, 'units2': 124, 'dropout_rate': 0.16251746922388588, 'learning_rate': 0.0006128543939250452, 'activation1': 'tanh', 'activation2': 'tanh', 'batch_size': 23, 'epochs': 34}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 01:40:58,753] Trial 3 finished with value: 0.8971609141909 and parameters: {'units1': 97, 'units2': 48, 'dropout_rate': 0.23422177397765528, 'learning_rate': 0.00025853491085397193, 'activation1': 'tanh', 'activation2': 'tanh', 'batch_size': 21, 'epochs': 46}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 01:46:24,631] Trial 4 finished with value: 0.8971609141909 and parameters: {'units1': 40, 'units2': 112, 'dropout_rate': 0.307249945082964, 'learning_rate': 0.00019071325251411884, 'activation1': 'tanh', 'activation2': 'relu', 'batch_size': 17, 'epochs': 35}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 01:48:04,958] Trial 5 finished with value: 0.8917612399059606 and parameters: {'units1': 36, 'units2': 92, 'dropout_rate': 0.15568076125523814, 'learning_rate': 0.0004799006187816481, 'activation1': 'relu', 'activation2': 'relu', 'batch_size': 51, 'epochs': 21}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 01:50:31,403] Trial 6 finished with value: 0.8971609141909 and parameters: {'units1': 126, 'units2': 76, 'dropout_rate': 0.43107954486823963, 'learning_rate': 0.018416003889166987, 'activation1': 'relu', 'activation2': 'sigmoid', 'batch_size': 22, 'epochs': 22}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 01:51:44,011] Trial 7 finished with value: 0.8971609141909 and parameters: {'units1': 112, 'units2': 44, 'dropout_rate': 0.14099993026012775, 'learning_rate': 1.9124898340788458e-05, 'activation1': 'sigmoid', 'activation2': 'sigmoid', 'batch_size': 53, 'epochs': 19}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 01:56:02,735] Trial 8 finished with value: 0.89707763193978 and parameters: {'units1': 64, 'units2': 126, 'dropout_rate': 0.2873902214795385, 'learning_rate': 0.0004084488183371958, 'activation1': 'relu', 'activation2': 'relu', 'batch_size': 27, 'epochs': 42}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 01:58:40,457] Trial 9 finished with value: 0.8971609141909 and parameters: {'units1': 41, 'units2': 42, 'dropout_rate': 0.1276711847452084, 'learning_rate': 0.000295125197913056, 'activation1': 'tanh', 'activation2': 'tanh', 'batch_size': 57, 'epochs': 43}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 01:59:39,897] Trial 10 finished with value: 0.8971609141909 and parameters: {'units1': 65, 'units2': 74, 'dropout_rate': 0.42498719314421873, 'learning_rate': 0.006877969040508156, 'activation1': 'tanh', 'activation2': 'sigmoid', 'batch_size': 34, 'epochs': 10}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 02:01:31,674] Trial 11 finished with value: 0.8971609141909 and parameters: {'units1': 79, 'units2': 63, 'dropout_rate': 0.3515555138700255, 'learning_rate': 2.7287238723735293e-05, 'activation1': 'sigmoid', 'activation2': 'tanh', 'batch_size': 43, 'epochs': 30}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 02:03:37,512] Trial 12 finished with value: 0.8971609141909 and parameters: {'units1': 92, 'units2': 93, 'dropout_rate': 0.23501841752775024, 'learning_rate': 0.002895221977894937, 'activation1': 'sigmoid', 'activation2': 'sigmoid', 'batch_size': 41, 'epochs': 31}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 02:06:18,070] Trial 13 finished with value: 0.8971609141909 and parameters: {'units1': 59, 'units2': 60, 'dropout_rate': 0.3761944713595094, 'learning_rate': 6.0369743318650166e-05, 'activation1': 'sigmoid', 'activation2': 'tanh', 'batch_size': 33, 'epochs': 38}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 02:07:53,822] Trial 14 finished with value: 0.8971609141909 and parameters: {'units1': 84, 'units2': 34, 'dropout_rate': 0.2347298071773568, 'learning_rate': 0.09929964725968884, 'activation1': 'sigmoid', 'activation2': 'sigmoid', 'batch_size': 47, 'epochs': 26}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 02:10:14,947] Trial 15 finished with value: 0.8971609141909 and parameters: {'units1': 51, 'units2': 93, 'dropout_rate': 0.4763308357364379, 'learning_rate': 5.5500842926456215e-05, 'activation1': 'tanh', 'activation2': 'tanh', 'batch_size': 63, 'epochs': 50}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 02:12:27,387] Trial 16 finished with value: 0.8971609141909 and parameters: {'units1': 123, 'units2': 59, 'dropout_rate': 0.2988696942265964, 'learning_rate': 0.0021080696260051606, 'activation1': 'sigmoid', 'activation2': 'sigmoid', 'batch_size': 32, 'epochs': 27}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 02:14:54,951] Trial 17 finished with value: 0.8971609141909 and parameters: {'units1': 82, 'units2': 32, 'dropout_rate': 0.20176126301048383, 'learning_rate': 9.469876622415633e-05, 'activation1': 'sigmoid', 'activation2': 'sigmoid', 'batch_size': 37, 'epochs': 38}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 02:16:11,651] Trial 18 finished with value: 0.8971609141909 and parameters: {'units1': 105, 'units2': 104, 'dropout_rate': 0.33230956258302397, 'learning_rate': 1.2470468871284501e-05, 'activation1': 'tanh', 'activation2': 'tanh', 'batch_size': 29, 'epochs': 13}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 02:17:51,914] Trial 19 finished with value: 0.8971609141909 and parameters: {'units1': 74, 'units2': 69, 'dropout_rate': 0.3985810421205009, 'learning_rate': 0.0014145406881445383, 'activation1': 'relu', 'activation2': 'relu', 'batch_size': 44, 'epochs': 26}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 02:20:06,484] Trial 20 finished with value: 0.8971609141909 and parameters: {'units1': 49, 'units2': 52, 'dropout_rate': 0.2618326010027371, 'learning_rate': 0.00011528342913377901, 'activation1': 'sigmoid', 'activation2': 'tanh', 'batch_size': 38, 'epochs': 35}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 02:23:39,796] Trial 21 finished with value: 0.8971609141909 and parameters: {'units1': 114, 'units2': 125, 'dropout_rate': 0.1674363794678507, 'learning_rate': 0.0006909708149058929, 'activation1': 'tanh', 'activation2': 'tanh', 'batch_size': 23, 'epochs': 33}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 02:28:04,223] Trial 22 finished with value: 0.8971609141909 and parameters: {'units1': 102, 'units2': 112, 'dropout_rate': 0.10553194850480346, 'learning_rate': 0.0010267653333487815, 'activation1': 'tanh', 'activation2': 'tanh', 'batch_size': 18, 'epochs': 39}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 02:31:18,089] Trial 23 finished with value: 0.8971609141909 and parameters: {'units1': 116, 'units2': 85, 'dropout_rate': 0.18870978346990663, 'learning_rate': 0.005469424594334248, 'activation1': 'tanh', 'activation2': 'tanh', 'batch_size': 27, 'epochs': 34}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 02:35:37,876] Trial 24 finished with value: 0.8971609141909 and parameters: {'units1': 93, 'units2': 102, 'dropout_rate': 0.20502699855344264, 'learning_rate': 4.305162605442419e-05, 'activation1': 'tanh', 'activation2': 'tanh', 'batch_size': 16, 'epochs': 28}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 02:39:42,226] Trial 25 finished with value: 0.8971609141909 and parameters: {'units1': 103, 'units2': 86, 'dropout_rate': 0.2670009774173101, 'learning_rate': 0.00016106126076606382, 'activation1': 'tanh', 'activation2': 'sigmoid', 'batch_size': 25, 'epochs': 40}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 1s 5ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 02:44:53,759] Trial 26 finished with value: 0.8971609141909 and parameters: {'units1': 89, 'units2': 68, 'dropout_rate': 0.3439820341854674, 'learning_rate': 0.0006871074248786332, 'activation1': 'tanh', 'activation2': 'tanh', 'batch_size': 20, 'epochs': 32}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 02:48:26,378] Trial 27 finished with value: 0.8971609141909 and parameters: {'units1': 110, 'units2': 117, 'dropout_rate': 0.1811732403166253, 'learning_rate': 8.610559007366684e-05, 'activation1': 'tanh', 'activation2': 'tanh', 'batch_size': 30, 'epochs': 45}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 02:50:32,355] Trial 28 finished with value: 0.8971609141909 and parameters: {'units1': 73, 'units2': 38, 'dropout_rate': 0.4947060776610121, 'learning_rate': 0.0038784558250998516, 'activation1': 'relu', 'activation2': 'relu', 'batch_size': 48, 'epochs': 36}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 02:52:28,176] Trial 29 finished with value: 0.8971609141909 and parameters: {'units1': 97, 'units2': 53, 'dropout_rate': 0.21537930259508833, 'learning_rate': 0.00024603703949171415, 'activation1': 'sigmoid', 'activation2': 'sigmoid', 'batch_size': 35, 'epochs': 24}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 02:57:54,998] Trial 30 finished with value: 0.8971609141909 and parameters: {'units1': 120, 'units2': 100, 'dropout_rate': 0.26447966014816054, 'learning_rate': 0.026995204340175088, 'activation1': 'tanh', 'activation2': 'tanh', 'batch_size': 20, 'epochs': 49}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 03:03:32,547] Trial 31 finished with value: 0.8971609141909 and parameters: {'units1': 98, 'units2': 50, 'dropout_rate': 0.3038820887183714, 'learning_rate': 0.00020077525504394626, 'activation1': 'tanh', 'activation2': 'tanh', 'batch_size': 17, 'epochs': 46}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 03:07:44,564] Trial 32 finished with value: 0.8971609141909 and parameters: {'units1': 107, 'units2': 45, 'dropout_rate': 0.24425467985938168, 'learning_rate': 0.0005368386045799144, 'activation1': 'tanh', 'activation2': 'tanh', 'batch_size': 24, 'epochs': 36}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 03:11:53,521] Trial 33 finished with value: 0.8971609141909 and parameters: {'units1': 33, 'units2': 55, 'dropout_rate': 0.16341995261993522, 'learning_rate': 0.0003014787109663654, 'activation1': 'tanh', 'activation2': 'relu', 'batch_size': 22, 'epochs': 29}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 03:20:20,633] Trial 34 finished with value: 0.8971609141909 and parameters: {'units1': 118, 'units2': 80, 'dropout_rate': 0.31840281997940695, 'learning_rate': 0.001448136387256067, 'activation1': 'tanh', 'activation2': 'tanh', 'batch_size': 19, 'epochs': 47}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 03:26:32,245] Trial 35 finished with value: 0.8971609141909 and parameters: {'units1': 128, 'units2': 46, 'dropout_rate': 0.13875321927209727, 'learning_rate': 3.0645842115373455e-05, 'activation1': 'relu', 'activation2': 'sigmoid', 'batch_size': 26, 'epochs': 42}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 6ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 1s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 03:28:38,319] Trial 36 finished with value: 0.8971609141909 and parameters: {'units1': 88, 'units2': 37, 'dropout_rate': 0.21870706145907495, 'learning_rate': 0.0001322719049901442, 'activation1': 'tanh', 'activation2': 'relu', 'batch_size': 54, 'epochs': 22}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 2s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 1s 15ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 03:34:31,153] Trial 37 finished with value: 0.8971609141909 and parameters: {'units1': 110, 'units2': 69, 'dropout_rate': 0.2804339203305448, 'learning_rate': 0.00035961079145928, 'activation1': 'relu', 'activation2': 'tanh', 'batch_size': 30, 'epochs': 44}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 6ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 8ms/step\n",
      "29/29 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 03:39:34,937] Trial 38 finished with value: 0.8971609141909 and parameters: {'units1': 99, 'units2': 76, 'dropout_rate': 0.3846860933305686, 'learning_rate': 0.000494047297429003, 'activation1': 'sigmoid', 'activation2': 'tanh', 'batch_size': 16, 'epochs': 19}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 7ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 03:46:27,840] Trial 39 finished with value: 0.8971609141909 and parameters: {'units1': 75, 'units2': 41, 'dropout_rate': 0.10285112605962482, 'learning_rate': 0.0008840362030765494, 'activation1': 'tanh', 'activation2': 'sigmoid', 'batch_size': 21, 'epochs': 41}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 9ms/step\n",
      "29/29 [==============================] - 1s 11ms/step\n",
      "29/29 [==============================] - 1s 7ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 03:51:22,430] Trial 40 finished with value: 0.8971609141909 and parameters: {'units1': 41, 'units2': 62, 'dropout_rate': 0.35793690302942277, 'learning_rate': 0.00020246497103015306, 'activation1': 'tanh', 'activation2': 'tanh', 'batch_size': 38, 'epochs': 32}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 1s 6ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 1s 8ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 03:58:06,904] Trial 41 finished with value: 0.8971609141909 and parameters: {'units1': 42, 'units2': 121, 'dropout_rate': 0.3063061586820873, 'learning_rate': 0.0003789820295754655, 'activation1': 'tanh', 'activation2': 'relu', 'batch_size': 23, 'epochs': 37}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 1s 16ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 04:03:38,520] Trial 42 finished with value: 0.8971609141909 and parameters: {'units1': 58, 'units2': 106, 'dropout_rate': 0.42117799904828335, 'learning_rate': 7.260987662404933e-05, 'activation1': 'tanh', 'activation2': 'relu', 'batch_size': 19, 'epochs': 30}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 04:07:00,878] Trial 43 finished with value: 0.8971609141909 and parameters: {'units1': 47, 'units2': 128, 'dropout_rate': 0.2447557936892299, 'learning_rate': 0.0001507153363229626, 'activation1': 'sigmoid', 'activation2': 'relu', 'batch_size': 42, 'epochs': 34}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 2s 22ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 1s 10ms/step\n",
      "29/29 [==============================] - 0s 6ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 04:10:20,759] Trial 44 finished with value: 0.8971609141909 and parameters: {'units1': 36, 'units2': 114, 'dropout_rate': 0.3213017052500213, 'learning_rate': 4.2919208516654234e-05, 'activation1': 'tanh', 'activation2': 'relu', 'batch_size': 46, 'epochs': 31}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 1s 18ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 04:14:35,388] Trial 45 finished with value: 0.8971609141909 and parameters: {'units1': 66, 'units2': 123, 'dropout_rate': 0.14960057075514124, 'learning_rate': 1.6376389176467298e-05, 'activation1': 'sigmoid', 'activation2': 'sigmoid', 'batch_size': 50, 'epochs': 39}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 6ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 04:20:30,791] Trial 46 finished with value: 0.8971609141909 and parameters: {'units1': 54, 'units2': 109, 'dropout_rate': 0.28716132683996753, 'learning_rate': 0.0018303622132486888, 'activation1': 'tanh', 'activation2': 'relu', 'batch_size': 27, 'epochs': 43}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 6ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 04:24:37,749] Trial 47 finished with value: 0.8971609141909 and parameters: {'units1': 122, 'units2': 119, 'dropout_rate': 0.36906926056831396, 'learning_rate': 0.00024557099859251686, 'activation1': 'relu', 'activation2': 'sigmoid', 'batch_size': 40, 'epochs': 35}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 1s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 04:27:02,631] Trial 48 finished with value: 0.8971609141909 and parameters: {'units1': 45, 'units2': 89, 'dropout_rate': 0.3352271296129742, 'learning_rate': 2.3904902375686272e-05, 'activation1': 'sigmoid', 'activation2': 'tanh', 'batch_size': 60, 'epochs': 24}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 04:32:25,897] Trial 49 finished with value: 0.8971609141909 and parameters: {'units1': 38, 'units2': 57, 'dropout_rate': 0.12361372264325647, 'learning_rate': 0.00010142627432721748, 'activation1': 'tanh', 'activation2': 'tanh', 'batch_size': 21, 'epochs': 29}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 04:36:17,242] Trial 50 finished with value: 0.8971609141909 and parameters: {'units1': 32, 'units2': 98, 'dropout_rate': 0.2304616637709836, 'learning_rate': 0.010707097819264473, 'activation1': 'tanh', 'activation2': 'sigmoid', 'batch_size': 16, 'epochs': 16}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 1s 8ms/step\n",
      "29/29 [==============================] - 1s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 04:38:36,221] Trial 51 finished with value: 0.8971609141909 and parameters: {'units1': 126, 'units2': 78, 'dropout_rate': 0.4369742811816119, 'learning_rate': 0.06689288421086331, 'activation1': 'relu', 'activation2': 'sigmoid', 'batch_size': 24, 'epochs': 10}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 6ms/step\n",
      "29/29 [==============================] - 0s 6ms/step\n",
      "29/29 [==============================] - 0s 6ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 7ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 04:45:56,243] Trial 52 finished with value: 0.8971609141909 and parameters: {'units1': 114, 'units2': 72, 'dropout_rate': 0.4506963317831465, 'learning_rate': 0.011174745473322813, 'activation1': 'relu', 'activation2': 'sigmoid', 'batch_size': 18, 'epochs': 33}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 7ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 6ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 04:50:44,325] Trial 53 finished with value: 0.8971609141909 and parameters: {'units1': 85, 'units2': 96, 'dropout_rate': 0.46849985683409145, 'learning_rate': 0.0008969164050336834, 'activation1': 'relu', 'activation2': 'sigmoid', 'batch_size': 28, 'epochs': 25}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 7ms/step\n",
      "29/29 [==============================] - 1s 8ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 04:53:10,808] Trial 54 finished with value: 0.8971609141909 and parameters: {'units1': 93, 'units2': 65, 'dropout_rate': 0.39043779498733183, 'learning_rate': 0.0004771503516209568, 'activation1': 'relu', 'activation2': 'sigmoid', 'batch_size': 32, 'epochs': 16}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 1s 24ms/step\n",
      "29/29 [==============================] - 1s 17ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 6ms/step\n",
      "29/29 [==============================] - 0s 7ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 04:58:32,012] Trial 55 finished with value: 0.8971609141909 and parameters: {'units1': 106, 'units2': 49, 'dropout_rate': 0.4082178744136169, 'learning_rate': 0.0006668931680490489, 'activation1': 'sigmoid', 'activation2': 'tanh', 'batch_size': 22, 'epochs': 27}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 1s 5ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 7ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 05:02:46,078] Trial 56 finished with value: 0.8971609141909 and parameters: {'units1': 112, 'units2': 85, 'dropout_rate': 0.18055869253361892, 'learning_rate': 0.003063279595716513, 'activation1': 'tanh', 'activation2': 'sigmoid', 'batch_size': 25, 'epochs': 22}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 6ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 05:05:59,377] Trial 57 finished with value: 0.8971609141909 and parameters: {'units1': 100, 'units2': 74, 'dropout_rate': 0.27729506155531963, 'learning_rate': 0.037887769746957914, 'activation1': 'sigmoid', 'activation2': 'tanh', 'batch_size': 35, 'epochs': 38}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 1s 10ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 09:51:25,576] Trial 58 finished with value: 0.8964095574131485 and parameters: {'units1': 68, 'units2': 80, 'dropout_rate': 0.24938247979831868, 'learning_rate': 5.74503661186687e-05, 'activation1': 'relu', 'activation2': 'relu', 'batch_size': 44, 'epochs': 48}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 09:56:31,690] Trial 59 finished with value: 0.89707763193978 and parameters: {'units1': 124, 'units2': 115, 'dropout_rate': 0.19636562662485885, 'learning_rate': 0.0001848866572571235, 'activation1': 'tanh', 'activation2': 'tanh', 'batch_size': 18, 'epochs': 31}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 10:00:50,747] Trial 60 finished with value: 0.8971609141909 and parameters: {'units1': 79, 'units2': 33, 'dropout_rate': 0.3579090302944342, 'learning_rate': 0.0003251436999928873, 'activation1': 'tanh', 'activation2': 'sigmoid', 'batch_size': 21, 'epochs': 36}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 10:02:22,975] Trial 61 finished with value: 0.8971609141909 and parameters: {'units1': 117, 'units2': 41, 'dropout_rate': 0.11729672665606601, 'learning_rate': 0.001224263657752796, 'activation1': 'sigmoid', 'activation2': 'sigmoid', 'batch_size': 53, 'epochs': 20}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 10:03:41,122] Trial 62 finished with value: 0.8971609141909 and parameters: {'units1': 104, 'units2': 45, 'dropout_rate': 0.13825951744103565, 'learning_rate': 1.2358214161112322e-05, 'activation1': 'sigmoid', 'activation2': 'sigmoid', 'batch_size': 59, 'epochs': 17}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 10:05:06,194] Trial 63 finished with value: 0.8971609141909 and parameters: {'units1': 109, 'units2': 49, 'dropout_rate': 0.15183061508003534, 'learning_rate': 1.7877792785226296e-05, 'activation1': 'sigmoid', 'activation2': 'sigmoid', 'batch_size': 56, 'epochs': 18}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 10:10:35,297] Trial 64 finished with value: 0.8971609141909 and parameters: {'units1': 96, 'units2': 62, 'dropout_rate': 0.21338143689933284, 'learning_rate': 4.447448211758623e-05, 'activation1': 'sigmoid', 'activation2': 'tanh', 'batch_size': 20, 'epochs': 33}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 10:11:49,630] Trial 65 finished with value: 0.8971609141909 and parameters: {'units1': 120, 'units2': 38, 'dropout_rate': 0.16584915111243817, 'learning_rate': 0.00025593761350156755, 'activation1': 'tanh', 'activation2': 'sigmoid', 'batch_size': 63, 'epochs': 13}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 1s 11ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 10:15:38,267] Trial 66 finished with value: 0.8971609141909 and parameters: {'units1': 115, 'units2': 90, 'dropout_rate': 0.2269161344972822, 'learning_rate': 0.00010501703980040183, 'activation1': 'sigmoid', 'activation2': 'tanh', 'batch_size': 23, 'epochs': 23}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 6ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 7ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 10:21:10,984] Trial 67 finished with value: 0.8971609141909 and parameters: {'units1': 112, 'units2': 57, 'dropout_rate': 0.18695028620557375, 'learning_rate': 7.585369095600206e-05, 'activation1': 'tanh', 'activation2': 'relu', 'batch_size': 17, 'epochs': 27}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 10:24:45,736] Trial 68 finished with value: 0.8969109667334874 and parameters: {'units1': 52, 'units2': 35, 'dropout_rate': 0.3148960981975036, 'learning_rate': 1.0060829803522777e-05, 'activation1': 'relu', 'activation2': 'tanh', 'batch_size': 50, 'epochs': 40}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 10:29:10,466] Trial 69 finished with value: 0.8971609141909 and parameters: {'units1': 102, 'units2': 83, 'dropout_rate': 0.4983062093534685, 'learning_rate': 3.0412596530499703e-05, 'activation1': 'tanh', 'activation2': 'sigmoid', 'batch_size': 30, 'epochs': 50}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 10:32:54,420] Trial 70 finished with value: 0.8971609141909 and parameters: {'units1': 108, 'units2': 67, 'dropout_rate': 0.34142968613856817, 'learning_rate': 0.0001375334333424628, 'activation1': 'sigmoid', 'activation2': 'tanh', 'batch_size': 25, 'epochs': 35}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 10:35:21,013] Trial 71 finished with value: 0.8971609141909 and parameters: {'units1': 42, 'units2': 42, 'dropout_rate': 0.11595860409639741, 'learning_rate': 0.00041375428577471846, 'activation1': 'tanh', 'activation2': 'tanh', 'batch_size': 57, 'epochs': 45}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 10:37:46,010] Trial 72 finished with value: 0.8971609141909 and parameters: {'units1': 37, 'units2': 47, 'dropout_rate': 0.1351180554328, 'learning_rate': 0.00027205749204141887, 'activation1': 'tanh', 'activation2': 'tanh', 'batch_size': 53, 'epochs': 42}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 10:40:09,334] Trial 73 finished with value: 0.8971609141909 and parameters: {'units1': 49, 'units2': 52, 'dropout_rate': 0.1753430365738628, 'learning_rate': 0.0007653392004548484, 'activation1': 'tanh', 'activation2': 'tanh', 'batch_size': 46, 'epochs': 37}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 10:42:36,210] Trial 74 finished with value: 0.8971609141909 and parameters: {'units1': 39, 'units2': 42, 'dropout_rate': 0.25468035561631064, 'learning_rate': 0.0005765508407397476, 'activation1': 'tanh', 'activation2': 'tanh', 'batch_size': 59, 'epochs': 47}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 10:44:27,498] Trial 75 finished with value: 0.8971609141909 and parameters: {'units1': 45, 'units2': 126, 'dropout_rate': 0.2965597077553655, 'learning_rate': 0.0001682853248978945, 'activation1': 'tanh', 'activation2': 'relu', 'batch_size': 55, 'epochs': 29}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 10:48:33,159] Trial 76 finished with value: 0.8971609141909 and parameters: {'units1': 56, 'units2': 109, 'dropout_rate': 0.12371247241250669, 'learning_rate': 0.0002094008024147581, 'activation1': 'tanh', 'activation2': 'tanh', 'batch_size': 19, 'epochs': 32}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 10:52:09,954] Trial 77 finished with value: 0.8971609141909 and parameters: {'units1': 35, 'units2': 38, 'dropout_rate': 0.27391503798632755, 'learning_rate': 0.0004116979246333556, 'activation1': 'tanh', 'activation2': 'sigmoid', 'batch_size': 32, 'epochs': 43}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 7ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 10:55:03,146] Trial 78 finished with value: 0.8971609141909 and parameters: {'units1': 62, 'units2': 54, 'dropout_rate': 0.1486853630838693, 'learning_rate': 0.00011797743008147414, 'activation1': 'sigmoid', 'activation2': 'tanh', 'batch_size': 40, 'epochs': 34}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 10:57:25,476] Trial 79 finished with value: 0.8971609141909 and parameters: {'units1': 95, 'units2': 72, 'dropout_rate': 0.20348510708336723, 'learning_rate': 0.0017239398100492305, 'activation1': 'relu', 'activation2': 'relu', 'batch_size': 17, 'epochs': 14}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 10:59:32,787] Trial 80 finished with value: 0.8971609141909 and parameters: {'units1': 90, 'units2': 45, 'dropout_rate': 0.3273752167119997, 'learning_rate': 0.00031883805130334357, 'activation1': 'tanh', 'activation2': 'sigmoid', 'batch_size': 61, 'epochs': 39}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 11:00:32,057] Trial 81 finished with value: 0.8971609141909 and parameters: {'units1': 46, 'units2': 77, 'dropout_rate': 0.42345221814046524, 'learning_rate': 0.023343498548702397, 'activation1': 'tanh', 'activation2': 'sigmoid', 'batch_size': 36, 'epochs': 10}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 6ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 11:02:07,406] Trial 82 finished with value: 0.8971609141909 and parameters: {'units1': 120, 'units2': 72, 'dropout_rate': 0.4492370330754707, 'learning_rate': 0.042398040075416615, 'activation1': 'tanh', 'activation2': 'sigmoid', 'batch_size': 22, 'epochs': 12}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 11:04:57,499] Trial 83 finished with value: 0.8971609141909 and parameters: {'units1': 62, 'units2': 35, 'dropout_rate': 0.37486581831315235, 'learning_rate': 0.006949572270409389, 'activation1': 'tanh', 'activation2': 'sigmoid', 'batch_size': 27, 'epochs': 30}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 11:07:25,200] Trial 84 finished with value: 0.8971609141909 and parameters: {'units1': 84, 'units2': 81, 'dropout_rate': 0.4034822031643095, 'learning_rate': 0.022401342220667007, 'activation1': 'tanh', 'activation2': 'sigmoid', 'batch_size': 20, 'epochs': 20}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 10ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 1s 17ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 11:10:41,089] Trial 85 finished with value: 0.8971609141909 and parameters: {'units1': 102, 'units2': 60, 'dropout_rate': 0.48113135200401214, 'learning_rate': 0.015060351062392653, 'activation1': 'tanh', 'activation2': 'tanh', 'batch_size': 34, 'epochs': 37}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 11:13:26,799] Trial 86 finished with value: 0.8971609141909 and parameters: {'units1': 69, 'units2': 123, 'dropout_rate': 0.4593815820600128, 'learning_rate': 0.0005480608319718557, 'activation1': 'sigmoid', 'activation2': 'sigmoid', 'batch_size': 24, 'epochs': 26}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 11:17:24,069] Trial 87 finished with value: 0.8971609141909 and parameters: {'units1': 40, 'units2': 75, 'dropout_rate': 0.41956267344538695, 'learning_rate': 0.0010813918708170718, 'activation1': 'tanh', 'activation2': 'tanh', 'batch_size': 29, 'epochs': 46}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 6ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 11:19:53,150] Trial 88 finished with value: 0.8971609141909 and parameters: {'units1': 76, 'units2': 66, 'dropout_rate': 0.29307276474810706, 'learning_rate': 0.008059617692226033, 'activation1': 'relu', 'activation2': 'relu', 'batch_size': 49, 'epochs': 41}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 11:22:25,610] Trial 89 finished with value: 0.8971609141909 and parameters: {'units1': 128, 'units2': 40, 'dropout_rate': 0.16026220810805003, 'learning_rate': 0.0029015571881578803, 'activation1': 'tanh', 'activation2': 'sigmoid', 'batch_size': 38, 'epochs': 34}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 6ms/step\n",
      "29/29 [==============================] - 0s 7ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 11:24:14,616] Trial 90 finished with value: 0.8971609141909 and parameters: {'units1': 111, 'units2': 103, 'dropout_rate': 0.4301722681499138, 'learning_rate': 0.004201954061666224, 'activation1': 'sigmoid', 'activation2': 'tanh', 'batch_size': 64, 'epochs': 28}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 11:26:09,230] Trial 91 finished with value: 0.8971609141909 and parameters: {'units1': 78, 'units2': 63, 'dropout_rate': 0.3599393370687304, 'learning_rate': 1.9952819455514446e-05, 'activation1': 'sigmoid', 'activation2': 'tanh', 'batch_size': 44, 'epochs': 30}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 11:28:19,442] Trial 92 finished with value: 0.8971609141909 and parameters: {'units1': 87, 'units2': 69, 'dropout_rate': 0.12967289718397787, 'learning_rate': 4.756658535877066e-05, 'activation1': 'sigmoid', 'activation2': 'tanh', 'batch_size': 43, 'epochs': 31}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 8ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 11:30:46,857] Trial 93 finished with value: 0.8971609141909 and parameters: {'units1': 106, 'units2': 43, 'dropout_rate': 0.34880253806707323, 'learning_rate': 7.191451372447792e-05, 'activation1': 'sigmoid', 'activation2': 'tanh', 'batch_size': 40, 'epochs': 35}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 11:32:56,230] Trial 94 finished with value: 0.8971609141909 and parameters: {'units1': 48, 'units2': 78, 'dropout_rate': 0.39441603845594353, 'learning_rate': 2.5697204443404932e-05, 'activation1': 'sigmoid', 'activation2': 'tanh', 'batch_size': 42, 'epochs': 32}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 11:39:57,051] Trial 95 finished with value: 0.8971609141909 and parameters: {'units1': 73, 'units2': 47, 'dropout_rate': 0.10020496451403432, 'learning_rate': 3.149553812260448e-05, 'activation1': 'tanh', 'activation2': 'sigmoid', 'batch_size': 19, 'epochs': 49}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 11:42:12,822] Trial 96 finished with value: 0.8971609141909 and parameters: {'units1': 43, 'units2': 51, 'dropout_rate': 0.41101298916565865, 'learning_rate': 1.3462943943974229e-05, 'activation1': 'relu', 'activation2': 'tanh', 'batch_size': 47, 'epochs': 38}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 11:43:40,678] Trial 97 finished with value: 0.8971609141909 and parameters: {'units1': 81, 'units2': 87, 'dropout_rate': 0.23867207953679104, 'learning_rate': 9.452536255091016e-05, 'activation1': 'sigmoid', 'activation2': 'relu', 'batch_size': 57, 'epochs': 25}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 11:45:37,021] Trial 98 finished with value: 0.8971609141909 and parameters: {'units1': 51, 'units2': 58, 'dropout_rate': 0.30883605870083336, 'learning_rate': 0.0002230991614919883, 'activation1': 'tanh', 'activation2': 'sigmoid', 'batch_size': 21, 'epochs': 15}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 11:48:27,050] Trial 99 finished with value: 0.8971609141909 and parameters: {'units1': 114, 'units2': 32, 'dropout_rate': 0.4410245360078482, 'learning_rate': 0.09217346685192589, 'activation1': 'tanh', 'activation2': 'tanh', 'batch_size': 17, 'epochs': 21}. Best is trial 0 with value: 0.8971609141909.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial value (Validation Loss): 0.8971609141909\n",
      "Best hyperparameters found:\n",
      "units1: 50\n",
      "units2: 75\n",
      "dropout_rate: 0.23212026912017683\n",
      "learning_rate: 0.000351999395296267\n",
      "activation1: tanh\n",
      "activation2: sigmoid\n",
      "batch_size: 19\n",
      "epochs: 31\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the best trial\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print(f\"Best trial value (Validation Loss): {best_trial.value}\")\n",
    "print(\"Best hyperparameters found:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 3ms/step\n",
      "F1:  0.8974358974358975\n",
      "23/23 [==============================] - 0s 2ms/step\n",
      "F1:  0.8966037735849056\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "F1:  0.8966037735849056\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "F1:  0.8972809667673716\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "F1:  0.8972809667673716\n",
      "23/23 [==============================] - 1s 36ms/step\n",
      "F1:  0.8972809667673716\n",
      "23/23 [==============================] - 0s 2ms/step\n",
      "F1:  0.8972809667673716\n",
      "23/23 [==============================] - 0s 2ms/step\n",
      "F1:  0.8972809667673716\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "F1:  0.8972809667673716\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "F1:  0.8972809667673716\n",
      "0.897161021197731\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "predictions_ann = []\n",
    "scores = []\n",
    "i=0\n",
    "\n",
    "fold=StratifiedKFold(n_splits=10,shuffle=True, random_state=1)\n",
    "\n",
    "for train_index, test_index in fold.split(train,y):\n",
    "    X_train, X_test = train.iloc[train_index], train.iloc[test_index]\n",
    "    Y_train, Y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "    model = Sequential([\n",
    "            Dense(50, activation='tanh', input_shape=(X_train.shape[1],)),\n",
    "            Dropout(0.23212026912017683),\n",
    "            Dense(75, activation='sigmoid'),\n",
    "            Dense(1, activation='sigmoid')  # For binary classification\n",
    "        ])\n",
    "\n",
    "        # Compile the model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.000351999395296267), \n",
    "                      loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Train the model with evaluation set\n",
    "    model.fit(X_train, Y_train, \n",
    "                  validation_data=(X_test, Y_test),  # Use test set as validation set\n",
    "                  epochs=31, \n",
    "                  batch_size=19, \n",
    "                  verbose=0)  # Set verbose=0 to silence output\n",
    "        \n",
    "    preds = (model.predict(X_test) > 0.5).astype(\"int32\")  # Convert probabilities to binary predictions\n",
    "    score = f1_score(Y_test,preds)\n",
    "    scores.append(score)\n",
    "    print(\"F1: \", score)\n",
    "    predictions_ann.append(classifier2.predict(test))\n",
    "    i=i+1\n",
    "print(np.mean(scores))\n",
    "\n",
    "#Trial 652 finished with value: 0.9687548448537013 and parameters: {'learning_rate': 0.1805243125886494, 'subsample': 0.2128564969905326, 'colsample_bytree': 0.5046224462041669, 'max_depth': 13, 'scale_pos_weight': 6, 'n_estimators': 995}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Aggregating predictions (e.g., majority voting if multiple predictions)\n",
    "final_predictions = np.mean(predictions_ann, axis=0)\n",
    "final_predictions = np.where(final_predictions > 0.5, 1, 0)\n",
    "\n",
    "# Preparing for submission (if needed)\n",
    "test_ann=pd.read_csv('Test Dataset.csv')\n",
    "sub_ann = pd.DataFrame({'ID': test_ann['id'], 'target': final_predictions})\n",
    "sub_ann.to_csv('win_ann.csv', index=False)\n",
    "print(\"Submission file created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
